{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import lightgbm as lgb\n",
                "from bayes_opt import BayesianOptimization\n",
                "from sklearn.datasets import load_boston\n",
                "from sklearn.metrics import r2_score, mean_squared_log_error, mean_squared_error\n",
                "import datetime as dt\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "from sklearn.model_selection import train_test_split"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data=pd.read_pickle(\"full_dataframe_20210803_150443.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index','event_id'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#data=data.head(200)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data.shape"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train, test = train_test_split(data, test_size=0.25, random_state=42)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
                "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "Y_train = train[\"COLLISSION_PROBABILITY_TARGET\"]\n",
                "X_train= train.drop([\"COLLISSION_PROBABILITY_TARGET\"], axis=1)\n",
                "Y_test = test[\"COLLISSION_PROBABILITY_TARGET\"]\n",
                "X_test= test.drop([\"COLLISSION_PROBABILITY_TARGET\"], axis=1)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def bayesian_opt_lgbm(X, y, init_iter=3, n_iters=7, random_state=11, seed = 101, num_iterations = 100):\n",
                "      dtrain = lgb.Dataset(data=X, label=y)\n",
                "      def lgb_r2_score(preds, dtrain):\n",
                "            labels = dtrain.get_label()\n",
                "            return 'r2', r2_score(labels, preds), True\n",
                "      # Objective Function\n",
                "      def hyp_lgbm(num_leaves, feature_fraction, learning_rate, bagging_fraction, max_depth, min_split_gain, min_child_weight):\n",
                "              params = {      'application':'regression',\n",
                "                              'num_iterations': num_iterations,\n",
                "                              'early_stopping_round':50,\n",
                "                              'verbose':-1,\n",
                "                              'metric':'lgb_r2_score'} # Default parameters\n",
                "              params[\"num_leaves\"] = int(round(num_leaves))\n",
                "              params[\"learning_rate\"] = learning_rate\n",
                "              params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
                "              params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
                "              params['max_depth'] = int(round(max_depth))\n",
                "              params['min_split_gain'] = min_split_gain\n",
                "              params['min_child_weight'] = min_child_weight\n",
                "              cv_results = lgb.cv(params, dtrain, nfold=5, seed=seed,categorical_feature=[], stratified=False,\n",
                "                                  verbose_eval =None, feval=lgb_r2_score)\n",
                "              #print(cv_results)\n",
                "              return np.max(cv_results['r2-mean'])\n",
                "    \n",
                "              # Domain space-- Range of hyperparameters \n",
                "      pds = {     'num_leaves': (80, 120),\n",
                "                  'feature_fraction': (0.1, 0.9),\n",
                "                  'bagging_fraction': (0.7, 1),\n",
                "                  'max_depth': (7, 15),\n",
                "                  'learning_rate':(0.001,0.05), \n",
                "                  'min_split_gain': (0.001, 0.1),\n",
                "                  'min_child_weight': (10, 25)\n",
                "                  }\n",
                "      # Surrogate model\n",
                "      optimizer = BayesianOptimization(hyp_lgbm, pds, random_state=random_state)\n",
                "                                          \n",
                "      # Optimize\n",
                "      optimizer.maximize(init_points=init_iter, n_iter=n_iters)\n",
                "\n",
                "      return optimizer\n",
                "\n",
                "bayesian_ouput=bayesian_opt_lgbm(X, y, init_iter=5, n_iters=10, random_state=77, seed = 101,num_iterations=1000)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "opt_parameters=bayesian_ouput.max['params']\n",
                "opt_parameters"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "filename=\"opt_parameters_{}.pkl\".format(dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
                "a_file = open(filename, \"wb\")\n",
                "\n",
                "pickle.dump(opt_parameters, a_file)\n",
                "\n",
                "a_file.close()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "a_file = open(filename,\"rb\")\n",
                "output = pickle.load(a_file)\n",
                "output"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#optimizer.max['params']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#'bagging_fraction': 1.0, 'feature_fraction': 0.9, 'max_depth': 8.0, 'min_child_weight': 25.0, 'min_split_gain': 0.013771321931506838, 'num_leaves': 88.93816438820497}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "hyper_params = {\n",
                "    'task': 'train',\n",
                "    'boosting_type': 'gbdt',\n",
                "    'objective': 'regression',\n",
                "    'metric': 'l2',\n",
                "    'learning_rate': opt_parameters.get(\"learning_rate\"),\n",
                "    'feature_fraction': opt_parameters.get(\"feature_fraction\"),\n",
                "    'bagging_fraction': opt_parameters.get(\"bagging_fraction\"),\n",
                "    #'bagging_freq': 10,\n",
                "    'verbose': -1,\n",
                "    \"max_depth\": int(round(opt_parameters.get(\"max_depth\"))),\n",
                "    \"num_leaves\": int(round(opt_parameters.get(\"num_leaves\"))),  \n",
                "    #\"max_bin\": 512,\n",
                "    'min_split_gain' : opt_parameters.get(\"min_split_gain\"),\n",
                "    \"num_iterations\": 500,\n",
                "    \"n_estimators\": 10,\n",
                "    'min_child_weight' : opt_parameters.get(\"min_child_weight\")\n",
                "}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Construct a gradient boosting model.\n",
                "gbm = lgb.LGBMRegressor(**hyper_params)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "lgbm_train = lgb.Dataset(X, label=y)\n",
                "lgbm_eval = lgb.Dataset(X_test, label=Y_test,reference=lgbm_train)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "gbm = lgb.train(params=hyper_params,\n",
                "                train_set=lgbm_train,\n",
                "                valid_sets=lgbm_eval,\n",
                "                verbose_eval=20,\n",
                "                #eval_metric='lgb_r2_score',\n",
                "                early_stopping_rounds=100)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#Build a gradient boosting model from the training set (X, y)\n",
                "\"\"\" gbm.fit(X, y,\n",
                "        eval_set=[(X_test, Y_test)],\n",
                "        eval_metric='l1',\n",
                "        early_stopping_rounds=50) \"\"\"\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "Y_pred = gbm.predict(X_train, num_iteration=gbm.best_iteration)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print('The r2 of prediction is:', r2_score(y, Y_pred))\n",
                "print('The MSE of prediction is:', mean_squared_error(y, Y_pred, squared=True))\n",
                "print('The RMSE of prediction is:', mean_squared_error(y, Y_pred, squared=False))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "aux_y=pd.DataFrame(y)\n",
                "aux_y.reset_index(inplace=True)\n",
                "aux_y.drop(['index'], inplace=True, axis=1)\n",
                "aux_y_pred=pd.DataFrame(Y_pred)\n",
                "aux_y_pred.reset_index(inplace=True)\n",
                "aux_y_pred.drop(['index'], inplace=True, axis=1)\n",
                "frames=[aux_y,aux_y_pred]\n",
                "result=pd.concat(frames,axis=1)\n",
                "result"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.6 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "2e85db0d6cccfdde710fbbd04098e00f256a22b321d8c0df509f8fabaad6d9ac"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}