{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_log_error, mean_squared_error,mean_absolute_error\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data=pd.read_pickle(\"./dataframe/df_only_risky_events.pkl\")\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(['index'], inplace=True, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train, test = train_test_split(data, test_size=0.30, random_state=42)\n",
    "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
    "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))\n",
    "Y_train = train[\"COLLISSION_PROBABILITY\"]\n",
    "X_train= train.drop([\"COLLISSION_PROBABILITY\"], axis=1)\n",
    "Y_test = test[\"COLLISSION_PROBABILITY\"]\n",
    "X_test= test.drop([\"COLLISSION_PROBABILITY\"], axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataframe dimension 190 x 86\n",
      "Test dataframe dimension 82 x 86\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Y = df[\"COLLISSION_PROBABILITY\"]\n",
    "# X = df.drop([\"COLLISSION_PROBABILITY\"], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ncol=X_train.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(ncol, input_dim=ncol, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(ncol, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_14498/1496378904.py:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
      "2021-11-29 22:17:44.050655: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-29 22:17:44.050697: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-29 22:17:44.050728: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (acer): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline: -1241113525154.00 (3613428639264.20) MSE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Convert into Numpy array\n",
    "samples_to_predict = np.array(X_test)\n",
    "\n",
    "# Generate predictions for samples\n",
    "predictions = baseline_model().predict(samples_to_predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-4.6100328e+05 -1.0118496e+04 -2.2740434e+05 ...  3.1287175e+05\n",
      "  -2.9365019e+05  5.5086875e+03]\n",
      " [-3.5896559e+05 -7.8521348e+03 -1.7700838e+05 ...  2.4318266e+05\n",
      "  -2.2841730e+05  4.3233008e+03]\n",
      " [-7.1781815e+06 -1.4698778e+05 -3.5488488e+06 ...  4.8832640e+06\n",
      "  -4.5815970e+06  8.7155000e+04]\n",
      " ...\n",
      " [-1.4230889e+05 -3.8034111e+03 -7.0003398e+04 ...  9.5515000e+04\n",
      "  -8.9830484e+04  1.5978125e+03]\n",
      " [-6.0426094e+04 -1.5592573e+03 -2.9299502e+04 ...  4.0671938e+04\n",
      "  -3.8239227e+04  8.0019336e+02]\n",
      " [-1.7707033e+02 -1.5145264e+01  1.1223202e+02 ...  3.7580349e+01\n",
      "   7.5259190e+00  1.0126320e+02]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "Y_pred = pd.DataFrame(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "Y_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.610033e+05</td>\n",
       "      <td>-10118.496094</td>\n",
       "      <td>-2.274043e+05</td>\n",
       "      <td>1.821591e+05</td>\n",
       "      <td>-18714.894531</td>\n",
       "      <td>-6.482261e+04</td>\n",
       "      <td>3.109068e+05</td>\n",
       "      <td>-4.064199e+05</td>\n",
       "      <td>-4.648611e+04</td>\n",
       "      <td>-5.374986e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.605469e+05</td>\n",
       "      <td>-6987.493164</td>\n",
       "      <td>9.331230e+04</td>\n",
       "      <td>-2.577813e+05</td>\n",
       "      <td>-1.137224e+05</td>\n",
       "      <td>3.605360e+05</td>\n",
       "      <td>-3.185858e+05</td>\n",
       "      <td>3.128718e+05</td>\n",
       "      <td>-2.936502e+05</td>\n",
       "      <td>5508.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.589656e+05</td>\n",
       "      <td>-7852.134766</td>\n",
       "      <td>-1.770084e+05</td>\n",
       "      <td>1.416559e+05</td>\n",
       "      <td>-14510.966797</td>\n",
       "      <td>-4.990900e+04</td>\n",
       "      <td>2.415592e+05</td>\n",
       "      <td>-3.160592e+05</td>\n",
       "      <td>-3.540011e+04</td>\n",
       "      <td>-4.188578e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.367406e+05</td>\n",
       "      <td>-5074.024414</td>\n",
       "      <td>7.309503e+04</td>\n",
       "      <td>-1.999858e+05</td>\n",
       "      <td>-8.807481e+04</td>\n",
       "      <td>2.807604e+05</td>\n",
       "      <td>-2.479054e+05</td>\n",
       "      <td>2.431827e+05</td>\n",
       "      <td>-2.284173e+05</td>\n",
       "      <td>4323.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.178182e+06</td>\n",
       "      <td>-146987.781250</td>\n",
       "      <td>-3.548849e+06</td>\n",
       "      <td>2.836030e+06</td>\n",
       "      <td>-291008.000000</td>\n",
       "      <td>-1.006685e+06</td>\n",
       "      <td>4.831710e+06</td>\n",
       "      <td>-6.329087e+06</td>\n",
       "      <td>-7.140054e+05</td>\n",
       "      <td>-8.374766e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.732084e+06</td>\n",
       "      <td>-105143.484375</td>\n",
       "      <td>1.456371e+06</td>\n",
       "      <td>-4.001235e+06</td>\n",
       "      <td>-1.758162e+06</td>\n",
       "      <td>5.611039e+06</td>\n",
       "      <td>-4.958682e+06</td>\n",
       "      <td>4.883264e+06</td>\n",
       "      <td>-4.581597e+06</td>\n",
       "      <td>87155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.490455e+05</td>\n",
       "      <td>-9586.560547</td>\n",
       "      <td>-2.215449e+05</td>\n",
       "      <td>1.775354e+05</td>\n",
       "      <td>-17790.609375</td>\n",
       "      <td>-6.298771e+04</td>\n",
       "      <td>3.029705e+05</td>\n",
       "      <td>-3.962183e+05</td>\n",
       "      <td>-4.485433e+04</td>\n",
       "      <td>-5.241582e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.462478e+05</td>\n",
       "      <td>-6775.270508</td>\n",
       "      <td>9.063627e+04</td>\n",
       "      <td>-2.507983e+05</td>\n",
       "      <td>-1.103341e+05</td>\n",
       "      <td>3.511869e+05</td>\n",
       "      <td>-3.106527e+05</td>\n",
       "      <td>3.050360e+05</td>\n",
       "      <td>-2.863832e+05</td>\n",
       "      <td>5445.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.076465e+04</td>\n",
       "      <td>-3079.177246</td>\n",
       "      <td>9.847783e+02</td>\n",
       "      <td>5.964138e+03</td>\n",
       "      <td>-5955.022461</td>\n",
       "      <td>-1.536927e+04</td>\n",
       "      <td>1.216793e+04</td>\n",
       "      <td>-5.597261e+03</td>\n",
       "      <td>-6.910667e+03</td>\n",
       "      <td>-8.193601e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.191292e+03</td>\n",
       "      <td>-3177.169189</td>\n",
       "      <td>-2.682387e+03</td>\n",
       "      <td>-1.611261e+04</td>\n",
       "      <td>-8.530089e+03</td>\n",
       "      <td>7.800210e+03</td>\n",
       "      <td>-8.698322e+03</td>\n",
       "      <td>4.170927e+03</td>\n",
       "      <td>-4.988652e+03</td>\n",
       "      <td>4371.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.328930e+07</td>\n",
       "      <td>-271081.562500</td>\n",
       "      <td>-6.572286e+06</td>\n",
       "      <td>5.251121e+06</td>\n",
       "      <td>-536453.750000</td>\n",
       "      <td>-1.863098e+06</td>\n",
       "      <td>8.945340e+06</td>\n",
       "      <td>-1.171562e+07</td>\n",
       "      <td>-1.321069e+06</td>\n",
       "      <td>-1.550772e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.616946e+07</td>\n",
       "      <td>-194652.218750</td>\n",
       "      <td>2.696046e+06</td>\n",
       "      <td>-7.406483e+06</td>\n",
       "      <td>-3.254999e+06</td>\n",
       "      <td>1.038809e+07</td>\n",
       "      <td>-9.181150e+06</td>\n",
       "      <td>9.040519e+06</td>\n",
       "      <td>-8.484158e+06</td>\n",
       "      <td>159341.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.267941e+05</td>\n",
       "      <td>-2800.457031</td>\n",
       "      <td>-6.232670e+04</td>\n",
       "      <td>4.998281e+04</td>\n",
       "      <td>-5456.924805</td>\n",
       "      <td>-1.801221e+04</td>\n",
       "      <td>8.534364e+04</td>\n",
       "      <td>-1.119400e+05</td>\n",
       "      <td>-1.272064e+04</td>\n",
       "      <td>-1.474222e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537297e+05</td>\n",
       "      <td>-1897.647217</td>\n",
       "      <td>2.560168e+04</td>\n",
       "      <td>-7.088012e+04</td>\n",
       "      <td>-3.118321e+04</td>\n",
       "      <td>9.914391e+04</td>\n",
       "      <td>-8.745861e+04</td>\n",
       "      <td>8.606563e+04</td>\n",
       "      <td>-8.057480e+04</td>\n",
       "      <td>1815.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-1.423089e+05</td>\n",
       "      <td>-3803.411133</td>\n",
       "      <td>-7.000340e+04</td>\n",
       "      <td>5.625019e+04</td>\n",
       "      <td>-5476.355469</td>\n",
       "      <td>-1.986033e+04</td>\n",
       "      <td>9.641595e+04</td>\n",
       "      <td>-1.252840e+05</td>\n",
       "      <td>-1.469947e+04</td>\n",
       "      <td>-1.660237e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.733298e+05</td>\n",
       "      <td>-1962.099121</td>\n",
       "      <td>2.867119e+04</td>\n",
       "      <td>-8.019757e+04</td>\n",
       "      <td>-3.563191e+04</td>\n",
       "      <td>1.116768e+05</td>\n",
       "      <td>-9.892466e+04</td>\n",
       "      <td>9.551500e+04</td>\n",
       "      <td>-8.983048e+04</td>\n",
       "      <td>1597.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-6.042609e+04</td>\n",
       "      <td>-1559.257324</td>\n",
       "      <td>-2.929950e+04</td>\n",
       "      <td>2.402442e+04</td>\n",
       "      <td>-2062.301758</td>\n",
       "      <td>-8.419811e+03</td>\n",
       "      <td>4.123842e+04</td>\n",
       "      <td>-5.357957e+04</td>\n",
       "      <td>-6.172764e+03</td>\n",
       "      <td>-7.069676e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>7.330170e+04</td>\n",
       "      <td>-1015.040649</td>\n",
       "      <td>1.172596e+04</td>\n",
       "      <td>-3.407288e+04</td>\n",
       "      <td>-1.494848e+04</td>\n",
       "      <td>4.733425e+04</td>\n",
       "      <td>-4.210920e+04</td>\n",
       "      <td>4.067194e+04</td>\n",
       "      <td>-3.823923e+04</td>\n",
       "      <td>800.193359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-1.770703e+02</td>\n",
       "      <td>-15.145264</td>\n",
       "      <td>1.122320e+02</td>\n",
       "      <td>8.438945e+01</td>\n",
       "      <td>32.841888</td>\n",
       "      <td>-6.225341e+01</td>\n",
       "      <td>3.440602e+02</td>\n",
       "      <td>-4.611678e+02</td>\n",
       "      <td>-3.135885e+01</td>\n",
       "      <td>-4.497466e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.887361e+02</td>\n",
       "      <td>-113.664680</td>\n",
       "      <td>-2.569294e+02</td>\n",
       "      <td>-3.658709e+02</td>\n",
       "      <td>-2.491591e+02</td>\n",
       "      <td>1.778124e+02</td>\n",
       "      <td>-2.980884e+02</td>\n",
       "      <td>3.758035e+01</td>\n",
       "      <td>7.525919e+00</td>\n",
       "      <td>101.263199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0              1             2             3              4   \\\n",
       "0  -4.610033e+05  -10118.496094 -2.274043e+05  1.821591e+05  -18714.894531   \n",
       "1  -3.589656e+05   -7852.134766 -1.770084e+05  1.416559e+05  -14510.966797   \n",
       "2  -7.178182e+06 -146987.781250 -3.548849e+06  2.836030e+06 -291008.000000   \n",
       "3  -4.490455e+05   -9586.560547 -2.215449e+05  1.775354e+05  -17790.609375   \n",
       "4  -1.076465e+04   -3079.177246  9.847783e+02  5.964138e+03   -5955.022461   \n",
       "..           ...            ...           ...           ...            ...   \n",
       "77 -1.328930e+07 -271081.562500 -6.572286e+06  5.251121e+06 -536453.750000   \n",
       "78 -1.267941e+05   -2800.457031 -6.232670e+04  4.998281e+04   -5456.924805   \n",
       "79 -1.423089e+05   -3803.411133 -7.000340e+04  5.625019e+04   -5476.355469   \n",
       "80 -6.042609e+04   -1559.257324 -2.929950e+04  2.402442e+04   -2062.301758   \n",
       "81 -1.770703e+02     -15.145264  1.122320e+02  8.438945e+01      32.841888   \n",
       "\n",
       "              5             6             7             8             9   ...  \\\n",
       "0  -6.482261e+04  3.109068e+05 -4.064199e+05 -4.648611e+04 -5.374986e+05  ...   \n",
       "1  -4.990900e+04  2.415592e+05 -3.160592e+05 -3.540011e+04 -4.188578e+05  ...   \n",
       "2  -1.006685e+06  4.831710e+06 -6.329087e+06 -7.140054e+05 -8.374766e+06  ...   \n",
       "3  -6.298771e+04  3.029705e+05 -3.962183e+05 -4.485433e+04 -5.241582e+05  ...   \n",
       "4  -1.536927e+04  1.216793e+04 -5.597261e+03 -6.910667e+03 -8.193601e+03  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "77 -1.863098e+06  8.945340e+06 -1.171562e+07 -1.321069e+06 -1.550772e+07  ...   \n",
       "78 -1.801221e+04  8.534364e+04 -1.119400e+05 -1.272064e+04 -1.474222e+05  ...   \n",
       "79 -1.986033e+04  9.641595e+04 -1.252840e+05 -1.469947e+04 -1.660237e+05  ...   \n",
       "80 -8.419811e+03  4.123842e+04 -5.357957e+04 -6.172764e+03 -7.069676e+04  ...   \n",
       "81 -6.225341e+01  3.440602e+02 -4.611678e+02 -3.135885e+01 -4.497466e+02  ...   \n",
       "\n",
       "              75             76            77            78            79  \\\n",
       "0   5.605469e+05   -6987.493164  9.331230e+04 -2.577813e+05 -1.137224e+05   \n",
       "1   4.367406e+05   -5074.024414  7.309503e+04 -1.999858e+05 -8.807481e+04   \n",
       "2   8.732084e+06 -105143.484375  1.456371e+06 -4.001235e+06 -1.758162e+06   \n",
       "3   5.462478e+05   -6775.270508  9.063627e+04 -2.507983e+05 -1.103341e+05   \n",
       "4   7.191292e+03   -3177.169189 -2.682387e+03 -1.611261e+04 -8.530089e+03   \n",
       "..           ...            ...           ...           ...           ...   \n",
       "77  1.616946e+07 -194652.218750  2.696046e+06 -7.406483e+06 -3.254999e+06   \n",
       "78  1.537297e+05   -1897.647217  2.560168e+04 -7.088012e+04 -3.118321e+04   \n",
       "79  1.733298e+05   -1962.099121  2.867119e+04 -8.019757e+04 -3.563191e+04   \n",
       "80  7.330170e+04   -1015.040649  1.172596e+04 -3.407288e+04 -1.494848e+04   \n",
       "81  2.887361e+02    -113.664680 -2.569294e+02 -3.658709e+02 -2.491591e+02   \n",
       "\n",
       "              80            81            82            83             84  \n",
       "0   3.605360e+05 -3.185858e+05  3.128718e+05 -2.936502e+05    5508.687500  \n",
       "1   2.807604e+05 -2.479054e+05  2.431827e+05 -2.284173e+05    4323.300781  \n",
       "2   5.611039e+06 -4.958682e+06  4.883264e+06 -4.581597e+06   87155.000000  \n",
       "3   3.511869e+05 -3.106527e+05  3.050360e+05 -2.863832e+05    5445.242188  \n",
       "4   7.800210e+03 -8.698322e+03  4.170927e+03 -4.988652e+03    4371.220703  \n",
       "..           ...           ...           ...           ...            ...  \n",
       "77  1.038809e+07 -9.181150e+06  9.040519e+06 -8.484158e+06  159341.250000  \n",
       "78  9.914391e+04 -8.745861e+04  8.606563e+04 -8.057480e+04    1815.507812  \n",
       "79  1.116768e+05 -9.892466e+04  9.551500e+04 -8.983048e+04    1597.812500  \n",
       "80  4.733425e+04 -4.210920e+04  4.067194e+04 -3.823923e+04     800.193359  \n",
       "81  1.778124e+02 -2.980884e+02  3.758035e+01  7.525919e+00     101.263199  \n",
       "\n",
       "[82 rows x 85 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "    # REGRESION MODEL METRICS\n",
    "    print(\"The r2 of prediction is:\", r2_score(Y_test, Y_pred))\n",
    "    print(\"The MSE of prediction is:\", mean_squared_error(Y_test, Y_pred, squared=True))\n",
    "    print(\n",
    "        \"The RMSE of prediction is:\", mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "    )\n",
    "    print(\"The MAE of prediction is:\", mean_absolute_error(Y_test, Y_pred))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=85)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14498/1019420739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# REGRESION MODEL METRICS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The r2 of prediction is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The MSE of prediction is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"The RMSE of prediction is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic-collision-avoidance/automatic-collision-detection/envs/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic-collision-avoidance/automatic-collision-detection/envs/lib/python3.9/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \"\"\"\n\u001b[0;32m--> 676\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    677\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    678\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/automatic-collision-avoidance/automatic-collision-detection/envs/lib/python3.9/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0m\u001b[1;32m    100\u001b[0m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=85)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (conda)"
  },
  "interpreter": {
   "hash": "6a229a7624aaca0bb64305d3a84f8aa11ea5a7132c8c99f127f8b64a260fdc5c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}