{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(5394, 85)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>__time_to_tca</th>\n",
                            "      <th>MISS_DISTANCE</th>\n",
                            "      <th>RELATIVE_SPEED</th>\n",
                            "      <th>RELATIVE_POSITION_R</th>\n",
                            "      <th>RELATIVE_POSITION_T</th>\n",
                            "      <th>RELATIVE_POSITION_N</th>\n",
                            "      <th>RELATIVE_VELOCITY_R</th>\n",
                            "      <th>RELATIVE_VELOCITY_T</th>\n",
                            "      <th>RELATIVE_VELOCITY_N</th>\n",
                            "      <th>COLLISSION_PROBABILITY</th>\n",
                            "      <th>...</th>\n",
                            "      <th>OBJECT2_CORR_CNDOT_TDOT</th>\n",
                            "      <th>PC_trend_1</th>\n",
                            "      <th>PC_trend_3</th>\n",
                            "      <th>PC_gradient_1</th>\n",
                            "      <th>PC_gradient_3</th>\n",
                            "      <th>MD_trend_1</th>\n",
                            "      <th>MD_trend_3</th>\n",
                            "      <th>MD_gradient_1</th>\n",
                            "      <th>MD_gradient_3</th>\n",
                            "      <th>TARGET_PC</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>5.775947</td>\n",
                            "      <td>568.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-20.9</td>\n",
                            "      <td>-562.8</td>\n",
                            "      <td>-75.9</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-5.415895</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.054742</td>\n",
                            "      <td>0.226170</td>\n",
                            "      <td>0.773872</td>\n",
                            "      <td>0.652610</td>\n",
                            "      <td>0.763062</td>\n",
                            "      <td>-123.0</td>\n",
                            "      <td>144.0</td>\n",
                            "      <td>-354.914301</td>\n",
                            "      <td>141.988456</td>\n",
                            "      <td>-5.345246</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>5.420762</td>\n",
                            "      <td>611.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-19.9</td>\n",
                            "      <td>-605.4</td>\n",
                            "      <td>-81.8</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-5.345246</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.029148</td>\n",
                            "      <td>0.070649</td>\n",
                            "      <td>0.237282</td>\n",
                            "      <td>0.198907</td>\n",
                            "      <td>0.234313</td>\n",
                            "      <td>43.0</td>\n",
                            "      <td>50.0</td>\n",
                            "      <td>121.063636</td>\n",
                            "      <td>49.374243</td>\n",
                            "      <td>-4.792366</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>5.119489</td>\n",
                            "      <td>576.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-9.6</td>\n",
                            "      <td>-571.2</td>\n",
                            "      <td>-77.4</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.792366</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.030920</td>\n",
                            "      <td>0.552880</td>\n",
                            "      <td>0.849700</td>\n",
                            "      <td>1.835148</td>\n",
                            "      <td>0.847141</td>\n",
                            "      <td>-35.0</td>\n",
                            "      <td>-115.0</td>\n",
                            "      <td>-116.173757</td>\n",
                            "      <td>-114.653689</td>\n",
                            "      <td>-4.208450</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4.750068</td>\n",
                            "      <td>328.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>2.7</td>\n",
                            "      <td>-325.3</td>\n",
                            "      <td>-43.7</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.208450</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.104064</td>\n",
                            "      <td>0.583916</td>\n",
                            "      <td>1.207445</td>\n",
                            "      <td>1.580622</td>\n",
                            "      <td>1.176985</td>\n",
                            "      <td>-248.0</td>\n",
                            "      <td>-240.0</td>\n",
                            "      <td>-671.319754</td>\n",
                            "      <td>-233.945596</td>\n",
                            "      <td>-4.049879</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>4.087221</td>\n",
                            "      <td>56.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>9.2</td>\n",
                            "      <td>-55.1</td>\n",
                            "      <td>-7.3</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.049879</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.117181</td>\n",
                            "      <td>0.158571</td>\n",
                            "      <td>1.295367</td>\n",
                            "      <td>0.239227</td>\n",
                            "      <td>0.971374</td>\n",
                            "      <td>-272.0</td>\n",
                            "      <td>-555.0</td>\n",
                            "      <td>-410.351242</td>\n",
                            "      <td>-416.185112</td>\n",
                            "      <td>-5.289798</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows Ã— 85 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   __time_to_tca  MISS_DISTANCE  RELATIVE_SPEED  RELATIVE_POSITION_R  \\\n",
                            "0       5.775947          568.0          2001.0                -20.9   \n",
                            "1       5.420762          611.0          2001.0                -19.9   \n",
                            "2       5.119489          576.0          2001.0                 -9.6   \n",
                            "3       4.750068          328.0          2001.0                  2.7   \n",
                            "4       4.087221           56.0          2001.0                  9.2   \n",
                            "\n",
                            "   RELATIVE_POSITION_T  RELATIVE_POSITION_N  RELATIVE_VELOCITY_R  \\\n",
                            "0               -562.8                -75.9                  0.8   \n",
                            "1               -605.4                -81.8                  0.8   \n",
                            "2               -571.2                -77.4                  0.8   \n",
                            "3               -325.3                -43.7                  0.5   \n",
                            "4                -55.1                 -7.3                  0.2   \n",
                            "\n",
                            "   RELATIVE_VELOCITY_T  RELATIVE_VELOCITY_N  COLLISSION_PROBABILITY  ...  \\\n",
                            "0               -268.6               1983.8               -5.415895  ...   \n",
                            "1               -268.6               1983.8               -5.345246  ...   \n",
                            "2               -268.6               1983.8               -4.792366  ...   \n",
                            "3               -268.6               1983.8               -4.208450  ...   \n",
                            "4               -268.6               1983.8               -4.049879  ...   \n",
                            "\n",
                            "   OBJECT2_CORR_CNDOT_TDOT  PC_trend_1  PC_trend_3  PC_gradient_1  \\\n",
                            "0                -0.054742    0.226170    0.773872       0.652610   \n",
                            "1                 0.029148    0.070649    0.237282       0.198907   \n",
                            "2                -0.030920    0.552880    0.849700       1.835148   \n",
                            "3                -0.104064    0.583916    1.207445       1.580622   \n",
                            "4                -0.117181    0.158571    1.295367       0.239227   \n",
                            "\n",
                            "   PC_gradient_3  MD_trend_1  MD_trend_3  MD_gradient_1  MD_gradient_3  \\\n",
                            "0       0.763062      -123.0       144.0    -354.914301     141.988456   \n",
                            "1       0.234313        43.0        50.0     121.063636      49.374243   \n",
                            "2       0.847141       -35.0      -115.0    -116.173757    -114.653689   \n",
                            "3       1.176985      -248.0      -240.0    -671.319754    -233.945596   \n",
                            "4       0.971374      -272.0      -555.0    -410.351242    -416.185112   \n",
                            "\n",
                            "   TARGET_PC  \n",
                            "0  -5.345246  \n",
                            "1  -4.792366  \n",
                            "2  -4.208450  \n",
                            "3  -4.049879  \n",
                            "4  -5.289798  \n",
                            "\n",
                            "[5 rows x 85 columns]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#./dataframe/df_only_risky_events.pkl\n",
                "#data=pd.read_pickle(\"dataframe/_PRUEBA_df_20211225_143242.pkl\") dataframe full 2022\n",
                "data=pd.read_pickle(\"dataframe/_PRUEBA_df_filtered_20220115_112153.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test = train_test_split(data, test_size=0.30, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train dataframe dimension 3775 x 85\n",
                        "Test dataframe dimension 1619 x 85\n"
                    ]
                }
            ],
            "source": [
                "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
                "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "columnt_to_predict_name=\"TARGET_PC\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "Y_train = train[columnt_to_predict_name]\n",
                "X_train= train.drop([columnt_to_predict_name], axis=1)\n",
                "Y_test = test[columnt_to_predict_name]\n",
                "X_test= test.drop([columnt_to_predict_name], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import RepeatedKFold\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.ensemble import AdaBoostRegressor\n",
                "import datetime as dt\n",
                "import pickle\n",
                "\n",
                "\n",
                "def grid_search_optimization(\n",
                "    X,\n",
                "    y,\n",
                "    n_estimators_list=[10, 50],\n",
                "    learning_rate_list=[0.0001, 0.001],\n",
                "    loss_functions_list = [\"linear\"],\n",
                "    scoring_metric=\"r2\",\n",
                "    n_splits_for_cv = 5,\n",
                "    n_repeats_for_cv = 3,\n",
                "    n_cores = -1\n",
                "):\n",
                "    \"\"\"Computes the optimal values for the LGBM model\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    X : dataframe\n",
                "        Train dataset\n",
                "    y : target dataframe\n",
                "        Values to be predicted\n",
                "    n_estimators_list: list\n",
                "        List of n_estimators values for grid search\n",
                "    learning_rate_list: list\n",
                "        List of learning_rate values for grid search\n",
                "    scoring_metric: \n",
                "        Scoring metrics from sci-kit learn default r2\n",
                "    n_splits_for_cv:\n",
                "        Number of splits for K Fold cross validation\n",
                "    n_repeats_for_cv:\n",
                "        Number of repetition for cross validation\n",
                "    n_cores: int\n",
                "        Number of CPU cores for computation. Default -1 = all\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    dictionary\n",
                "        Optimized values\n",
                "    \"\"\"\n",
                "    # define the model with default hyperparameters\n",
                "    model = AdaBoostRegressor()\n",
                "    # define the grid of values to search\n",
                "    grid = dict()\n",
                "    grid['n_estimators'] = n_estimators_list\n",
                "    grid['learning_rate'] = learning_rate_list\n",
                "    grid['loss'] = loss_functions_list\n",
                "    # define the evaluation procedure\n",
                "    cv = RepeatedKFold(n_splits=n_splits_for_cv, n_repeats=n_repeats_for_cv, random_state=1)\n",
                "    # define the grid search procedure\n",
                "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs= n_cores, cv=cv, scoring=scoring_metric,verbose=10)\n",
                "\n",
                "    # execute the grid search\n",
                "    grid_result = grid_search.fit(X, y)\n",
                "\n",
                "    # summarize the best score and configuration\n",
                "    now=dt.datetime.now()\n",
                "    filename1=\"./opt_parameters_ada_boost/{}_{}_gs_opt_param.pkl\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    filename2=\"./opt_parameters_ada_boost/{}_gs_full_run.txt\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    with open(filename1, \"wb\") as optimal_parameters_logger:\n",
                "        output_dict = grid_result.best_params_\n",
                "        output_dict[\"scoring\"] = scoring_metric\n",
                "        output_dict[\"best_score\"] = grid_result.best_score_\n",
                "        output_dict[\"n_splits\"] = n_splits_for_cv\n",
                "        output_dict[\"n_repeats\"] = n_repeats_for_cv\n",
                "        pickle.dump(output_dict, optimal_parameters_logger)\n",
                "        optimal_parameters_logger.close()\n",
                "    with open(filename2, \"a\") as results_logger:\n",
                "        output_1 = \"Best: {} using {} \\n\".format(grid_result.best_score_, grid_result.best_params_)\n",
                "        print(output_1)\n",
                "        results_logger.write(output_1)\n",
                "        # summarize all scores that were evaluated\n",
                "        means = grid_result.cv_results_['mean_test_score']\n",
                "        stds = grid_result.cv_results_['std_test_score']\n",
                "        params = grid_result.cv_results_['params']\n",
                "        for mean, stdev, param in zip(means, stds, params):\n",
                "            output_2 = \"{} ({}) with: {} \\n\".format(mean, stdev, param)\n",
                "            print(output_2)\n",
                "            results_logger.write(output_2)\n",
                "        results_logger.close()\n",
                "    return output_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_estimators_v = [100,300,500,800,1000,1500,2000,3000,4000,5000]\n",
                "learning_rate_v=[0.01,0.03,0.05]\n",
                "#n_estimators_v = [100,300,500]\n",
                "#learning_rate_v=[0.01]\n",
                "loss_function_v = [\"exponential\"]\n",
                "#regression_metrics=[\"neg_root_mean_squared_error\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 15 folds for each of 30 candidates, totalling 450 fits\n",
                        "[CV 3/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 1/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 2/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 4/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 3/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.731 total time=  10.4s\n",
                        "[CV 5/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 2/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.764 total time=  10.4s\n",
                        "[CV 6/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 4/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.699 total time=  11.9s\n",
                        "[CV 7/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 1/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.770 total time=  12.5s\n",
                        "[CV 8/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 5/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.780 total time=  11.3s\n",
                        "[CV 9/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100....\n",
                        "[CV 6/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.736 total time=  11.9s\n",
                        "[CV 10/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 8/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.762 total time=  10.6s\n",
                        "[CV 11/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 7/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.725 total time=  12.1s\n",
                        "[CV 12/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 10/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.736 total time=   9.7s\n",
                        "[CV 13/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 9/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.775 total time=  12.1s\n",
                        "[CV 14/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 11/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.763 total time=  12.0s\n",
                        "[CV 12/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.790 total time=  10.9s\n",
                        "[CV 15/15; 1/30] START learning_rate=0.01, loss=exponential, n_estimators=100...\n",
                        "[CV 1/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 13/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.746 total time=  11.6s\n",
                        "[CV 2/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 14/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.704 total time=  10.0s\n",
                        "[CV 3/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 15/15; 1/30] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=0.719 total time=  11.8s\n",
                        "[CV 4/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 1/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.773 total time=  31.9s\n",
                        "[CV 5/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 2/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.764 total time=  34.0s\n",
                        "[CV 6/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 3/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.729 total time=  34.4s\n",
                        "[CV 7/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 4/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.695 total time=  34.2s\n",
                        "[CV 8/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 5/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.774 total time=  34.8s\n",
                        "[CV 9/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300....\n",
                        "[CV 7/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.720 total time=  35.8s\n",
                        "[CV 10/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 6/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.739 total time=  39.2s\n",
                        "[CV 11/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 8/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.760 total time=  39.0s\n",
                        "[CV 12/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 9/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.775 total time=  38.9s\n",
                        "[CV 13/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 10/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.732 total time=  36.2s\n",
                        "[CV 14/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 11/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.761 total time=  39.3s\n",
                        "[CV 15/15; 2/30] START learning_rate=0.01, loss=exponential, n_estimators=300...\n",
                        "[CV 12/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.787 total time=  38.5s\n",
                        "[CV 1/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 13/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.741 total time=  38.9s\n",
                        "[CV 2/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 14/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.700 total time=  34.9s\n",
                        "[CV 3/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 15/15; 2/30] END learning_rate=0.01, loss=exponential, n_estimators=300;, score=0.727 total time=  38.0s\n",
                        "[CV 4/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 1/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.769 total time= 1.1min\n",
                        "[CV 5/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 2/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.756 total time= 1.1min\n",
                        "[CV 6/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 3/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.731 total time= 1.1min\n",
                        "[CV 7/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 4/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.695 total time= 1.1min\n",
                        "[CV 8/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 5/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.770 total time= 1.1min\n",
                        "[CV 9/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500....\n",
                        "[CV 6/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.735 total time= 1.1min\n",
                        "[CV 10/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 7/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.713 total time= 1.1min\n",
                        "[CV 11/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 8/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.759 total time= 1.1min\n",
                        "[CV 12/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 9/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.769 total time=  56.9s\n",
                        "[CV 13/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 10/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.729 total time=  52.9s\n",
                        "[CV 14/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 11/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.756 total time=  53.2s\n",
                        "[CV 15/15; 3/30] START learning_rate=0.01, loss=exponential, n_estimators=500...\n",
                        "[CV 12/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.778 total time=  52.9s\n",
                        "[CV 1/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 13/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.741 total time=  52.1s\n",
                        "[CV 2/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 14/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.697 total time=  52.0s\n",
                        "[CV 3/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 15/15; 3/30] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=0.728 total time=  51.7s\n",
                        "[CV 4/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 1/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.759 total time= 1.3min\n",
                        "[CV 5/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 2/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.739 total time= 1.3min\n",
                        "[CV 6/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 3/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.724 total time= 1.3min\n",
                        "[CV 7/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 4/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.686 total time= 1.3min\n",
                        "[CV 8/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 5/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.760 total time= 1.3min\n",
                        "[CV 9/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800....\n",
                        "[CV 6/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.723 total time= 1.4min\n",
                        "[CV 10/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 7/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.702 total time= 1.3min\n",
                        "[CV 11/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 8/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.752 total time= 1.3min\n",
                        "[CV 12/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 9/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.755 total time= 1.4min\n",
                        "[CV 13/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 10/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.721 total time= 1.3min\n",
                        "[CV 14/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 11/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.746 total time= 1.3min\n",
                        "[CV 15/15; 4/30] START learning_rate=0.01, loss=exponential, n_estimators=800...\n",
                        "[CV 12/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.758 total time= 1.4min\n",
                        "[CV 1/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 13/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.729 total time= 1.4min\n",
                        "[CV 2/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 14/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.694 total time= 1.4min\n",
                        "[CV 3/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 15/15; 4/30] END learning_rate=0.01, loss=exponential, n_estimators=800;, score=0.721 total time= 1.4min\n",
                        "[CV 4/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 1/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.750 total time= 1.6min\n",
                        "[CV 5/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 2/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.725 total time= 1.6min\n",
                        "[CV 6/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 3/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.717 total time= 1.7min\n",
                        "[CV 7/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 4/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.679 total time= 1.6min\n",
                        "[CV 8/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 5/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.748 total time= 1.7min\n",
                        "[CV 9/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000...\n",
                        "[CV 6/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.709 total time= 1.7min\n",
                        "[CV 10/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 7/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.693 total time= 1.6min\n",
                        "[CV 11/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 8/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.743 total time= 1.7min\n",
                        "[CV 12/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 9/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.743 total time= 1.7min\n",
                        "[CV 13/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 10/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.716 total time= 1.7min\n",
                        "[CV 14/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 11/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.740 total time= 1.7min\n",
                        "[CV 15/15; 5/30] START learning_rate=0.01, loss=exponential, n_estimators=1000..\n",
                        "[CV 12/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.743 total time= 1.7min\n",
                        "[CV 1/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 13/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.716 total time= 1.7min\n",
                        "[CV 2/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 14/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.688 total time= 1.7min\n",
                        "[CV 3/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 15/15; 5/30] END learning_rate=0.01, loss=exponential, n_estimators=1000;, score=0.714 total time= 1.7min\n",
                        "[CV 4/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 1/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.719 total time= 2.4min\n",
                        "[CV 5/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 2/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.686 total time= 2.4min\n",
                        "[CV 6/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 3/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.696 total time= 2.4min\n",
                        "[CV 7/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 4/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.657 total time= 2.4min\n",
                        "[CV 8/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 5/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.724 total time= 2.4min\n",
                        "[CV 9/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500...\n",
                        "[CV 6/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.678 total time= 2.4min\n",
                        "[CV 10/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 7/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.677 total time= 2.4min\n",
                        "[CV 11/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 8/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.715 total time= 2.4min\n",
                        "[CV 12/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 9/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.708 total time= 2.4min\n",
                        "[CV 13/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 10/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.698 total time= 2.4min\n",
                        "[CV 14/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 11/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.718 total time= 2.4min\n",
                        "[CV 15/15; 6/30] START learning_rate=0.01, loss=exponential, n_estimators=1500..\n",
                        "[CV 12/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.703 total time= 2.4min\n",
                        "[CV 1/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 13/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.676 total time= 2.4min\n",
                        "[CV 2/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 14/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.669 total time= 2.4min\n",
                        "[CV 3/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 15/15; 6/30] END learning_rate=0.01, loss=exponential, n_estimators=1500;, score=0.696 total time= 2.4min\n",
                        "[CV 4/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 1/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.694 total time= 3.0min\n",
                        "[CV 5/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 2/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.652 total time= 3.0min\n",
                        "[CV 6/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 3/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.671 total time= 3.0min\n",
                        "[CV 7/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 4/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.639 total time= 3.0min\n",
                        "[CV 8/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 5/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.707 total time= 3.0min\n",
                        "[CV 9/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000...\n",
                        "[CV 6/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.651 total time= 3.1min\n",
                        "[CV 10/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 7/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.658 total time= 3.0min\n",
                        "[CV 11/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 8/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.691 total time= 3.0min\n",
                        "[CV 12/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 9/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.680 total time= 3.1min\n",
                        "[CV 13/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 10/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.677 total time= 3.1min\n",
                        "[CV 14/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 11/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.695 total time= 3.1min\n",
                        "[CV 15/15; 7/30] START learning_rate=0.01, loss=exponential, n_estimators=2000..\n",
                        "[CV 12/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.673 total time= 3.1min\n",
                        "[CV 1/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 13/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.646 total time= 3.1min\n",
                        "[CV 2/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 14/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.650 total time= 3.0min\n",
                        "[CV 3/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 15/15; 7/30] END learning_rate=0.01, loss=exponential, n_estimators=2000;, score=0.680 total time= 3.1min\n",
                        "[CV 4/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 1/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.654 total time= 4.2min\n",
                        "[CV 5/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 2/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.605 total time= 4.3min\n",
                        "[CV 6/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 3/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.638 total time= 4.2min\n",
                        "[CV 7/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 4/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.616 total time= 4.2min\n",
                        "[CV 8/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 5/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.681 total time= 4.3min\n",
                        "[CV 9/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000...\n",
                        "[CV 6/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.607 total time= 4.2min\n",
                        "[CV 10/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 7/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.631 total time= 4.2min\n",
                        "[CV 11/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 8/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.652 total time= 4.2min\n",
                        "[CV 12/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 9/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.649 total time= 4.2min\n",
                        "[CV 13/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 10/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.643 total time= 4.2min\n",
                        "[CV 14/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 11/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.652 total time= 4.2min\n",
                        "[CV 15/15; 8/30] START learning_rate=0.01, loss=exponential, n_estimators=3000..\n",
                        "[CV 12/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.625 total time= 4.2min\n",
                        "[CV 1/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 13/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.594 total time= 4.2min\n",
                        "[CV 2/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 14/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.621 total time= 4.2min\n",
                        "[CV 3/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 15/15; 8/30] END learning_rate=0.01, loss=exponential, n_estimators=3000;, score=0.654 total time= 4.3min\n",
                        "[CV 4/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 1/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.626 total time= 5.3min\n",
                        "[CV 5/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 2/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.574 total time= 5.3min\n",
                        "[CV 6/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 3/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.611 total time= 5.3min\n",
                        "[CV 7/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 4/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.600 total time= 5.3min\n",
                        "[CV 8/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 5/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.665 total time= 5.4min\n",
                        "[CV 9/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000...\n",
                        "[CV 6/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.575 total time= 5.4min\n",
                        "[CV 10/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 7/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.611 total time= 5.3min\n",
                        "[CV 11/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 8/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.625 total time= 5.3min\n",
                        "[CV 12/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 9/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.613 total time= 5.3min\n",
                        "[CV 13/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 10/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.615 total time= 5.3min\n",
                        "[CV 14/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 11/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.621 total time= 5.3min\n",
                        "[CV 15/15; 9/30] START learning_rate=0.01, loss=exponential, n_estimators=4000..\n",
                        "[CV 12/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.597 total time= 5.4min\n",
                        "[CV 1/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 13/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.563 total time= 5.3min\n",
                        "[CV 2/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 14/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.602 total time= 5.2min\n",
                        "[CV 3/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 15/15; 9/30] END learning_rate=0.01, loss=exponential, n_estimators=4000;, score=0.639 total time= 5.3min\n",
                        "[CV 4/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 1/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.603 total time= 6.4min\n",
                        "[CV 5/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 2/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.555 total time= 6.4min\n",
                        "[CV 6/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 3/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.584 total time= 6.3min\n",
                        "[CV 7/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 4/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.589 total time= 6.3min\n",
                        "[CV 8/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 5/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.648 total time= 6.4min\n",
                        "[CV 9/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000..\n",
                        "[CV 6/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.549 total time= 6.4min\n",
                        "[CV 10/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 7/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.595 total time= 6.4min\n",
                        "[CV 11/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 8/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.609 total time= 6.3min\n",
                        "[CV 12/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 9/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.587 total time= 6.3min\n",
                        "[CV 13/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 10/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.594 total time= 6.3min\n",
                        "[CV 14/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 11/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.588 total time= 6.4min\n",
                        "[CV 15/15; 10/30] START learning_rate=0.01, loss=exponential, n_estimators=5000.\n",
                        "[CV 12/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.573 total time= 6.4min\n",
                        "[CV 1/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 1/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.770 total time=  11.4s\n",
                        "[CV 2/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 2/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.763 total time=  11.0s\n",
                        "[CV 3/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 3/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.730 total time=  10.8s\n",
                        "[CV 4/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 4/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.696 total time=  11.2s\n",
                        "[CV 5/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 5/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.776 total time=  10.9s\n",
                        "[CV 6/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 6/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.737 total time=  11.1s\n",
                        "[CV 7/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 7/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.717 total time=  10.9s\n",
                        "[CV 8/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 8/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.759 total time=  10.9s\n",
                        "[CV 9/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100...\n",
                        "[CV 9/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.774 total time=  11.0s\n",
                        "[CV 10/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 10/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.733 total time=  10.9s\n",
                        "[CV 11/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 13/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.545 total time= 6.3min\n",
                        "[CV 12/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 11/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.760 total time=  10.9s\n",
                        "[CV 13/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 12/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.786 total time=  10.9s\n",
                        "[CV 14/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 13/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.737 total time=  11.1s\n",
                        "[CV 15/15; 11/30] START learning_rate=0.03, loss=exponential, n_estimators=100..\n",
                        "[CV 14/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.701 total time=  11.3s\n",
                        "[CV 1/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 15/15; 11/30] END learning_rate=0.03, loss=exponential, n_estimators=100;, score=0.727 total time=  11.1s\n",
                        "[CV 2/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 1/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.755 total time=  31.1s\n",
                        "[CV 3/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 2/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.732 total time=  31.2s\n",
                        "[CV 4/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 3/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.722 total time=  31.2s\n",
                        "[CV 5/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 4/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.681 total time=  31.1s\n",
                        "[CV 6/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 14/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.580 total time= 6.3min\n",
                        "[CV 7/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 5/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.752 total time=  30.7s\n",
                        "[CV 8/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 6/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.716 total time=  30.8s\n",
                        "[CV 9/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300...\n",
                        "[CV 7/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.696 total time=  30.8s\n",
                        "[CV 10/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.747 total time=  31.4s\n",
                        "[CV 11/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 9/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.751 total time=  30.9s\n",
                        "[CV 12/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 10/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.719 total time=  30.8s\n",
                        "[CV 13/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 11/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.745 total time=  30.8s\n",
                        "[CV 14/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 12/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.750 total time=  30.8s\n",
                        "[CV 15/15; 12/30] START learning_rate=0.03, loss=exponential, n_estimators=300..\n",
                        "[CV 13/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.723 total time=  30.3s\n",
                        "[CV 1/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 15/15; 10/30] END learning_rate=0.01, loss=exponential, n_estimators=5000;, score=0.626 total time= 6.3min\n",
                        "[CV 2/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 14/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.692 total time=  30.9s\n",
                        "[CV 3/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 15/15; 12/30] END learning_rate=0.03, loss=exponential, n_estimators=300;, score=0.717 total time=  31.1s\n",
                        "[CV 4/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 1/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.716 total time=  47.7s\n",
                        "[CV 5/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 2/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.689 total time=  48.3s\n",
                        "[CV 6/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 3/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.695 total time=  47.7s\n",
                        "[CV 7/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 4/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.656 total time=  47.5s\n",
                        "[CV 8/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 5/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.724 total time=  47.8s\n",
                        "[CV 9/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500...\n",
                        "[CV 6/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.678 total time=  48.3s\n",
                        "[CV 10/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 7/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.677 total time=  47.9s\n",
                        "[CV 11/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 8/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.713 total time=  47.6s\n",
                        "[CV 12/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 9/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.713 total time=  47.5s\n",
                        "[CV 13/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 10/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.700 total time=  47.7s\n",
                        "[CV 14/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 11/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.715 total time=  48.0s\n",
                        "[CV 15/15; 13/30] START learning_rate=0.03, loss=exponential, n_estimators=500..\n",
                        "[CV 12/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.703 total time=  48.6s\n",
                        "[CV 1/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 13/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.674 total time=  47.9s\n",
                        "[CV 2/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 14/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.666 total time=  47.9s\n",
                        "[CV 3/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 15/15; 13/30] END learning_rate=0.03, loss=exponential, n_estimators=500;, score=0.695 total time=  47.9s\n",
                        "[CV 4/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 1/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.678 total time= 1.2min\n",
                        "[CV 5/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 2/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.629 total time= 1.2min\n",
                        "[CV 6/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 3/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.659 total time= 1.2min\n",
                        "[CV 7/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 4/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.628 total time= 1.2min\n",
                        "[CV 8/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 5/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.699 total time= 1.2min\n",
                        "[CV 9/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800...\n",
                        "[CV 6/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.635 total time= 1.2min\n",
                        "[CV 10/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 7/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.650 total time= 1.2min\n",
                        "[CV 11/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 8/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.672 total time= 1.2min\n",
                        "[CV 12/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 9/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.667 total time= 1.2min\n",
                        "[CV 13/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 10/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.662 total time= 1.2min\n",
                        "[CV 14/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 11/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.672 total time= 1.2min\n",
                        "[CV 15/15; 14/30] START learning_rate=0.03, loss=exponential, n_estimators=800..\n",
                        "[CV 12/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.652 total time= 1.2min\n",
                        "[CV 1/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 13/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.621 total time= 1.2min\n",
                        "[CV 2/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 14/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.641 total time= 1.2min\n",
                        "[CV 3/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 15/15; 14/30] END learning_rate=0.03, loss=exponential, n_estimators=800;, score=0.670 total time= 1.2min\n",
                        "[CV 4/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 1/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.657 total time= 1.4min\n",
                        "[CV 5/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 2/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.607 total time= 1.4min\n",
                        "[CV 6/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 3/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.640 total time= 1.4min\n",
                        "[CV 7/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 4/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.618 total time= 1.4min\n",
                        "[CV 8/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 5/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.687 total time= 1.4min\n",
                        "[CV 9/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000..\n",
                        "[CV 6/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.604 total time= 1.4min\n",
                        "[CV 10/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 7/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.633 total time= 1.4min\n",
                        "[CV 11/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 8/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.650 total time= 1.4min\n",
                        "[CV 12/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 9/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.646 total time= 1.4min\n",
                        "[CV 13/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 10/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.644 total time= 1.4min\n",
                        "[CV 14/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 11/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.658 total time= 1.4min\n",
                        "[CV 15/15; 15/30] START learning_rate=0.03, loss=exponential, n_estimators=1000.\n",
                        "[CV 12/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.627 total time= 1.4min\n",
                        "[CV 1/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 13/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.600 total time= 1.4min\n",
                        "[CV 2/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 14/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.619 total time= 1.4min\n",
                        "[CV 3/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 15/15; 15/30] END learning_rate=0.03, loss=exponential, n_estimators=1000;, score=0.651 total time= 1.4min\n",
                        "[CV 4/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 1/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.611 total time= 1.9min\n",
                        "[CV 5/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 2/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.561 total time= 2.0min\n",
                        "[CV 6/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 3/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.594 total time= 2.0min\n",
                        "[CV 7/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 4/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.596 total time= 2.0min\n",
                        "[CV 8/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 5/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.652 total time= 2.0min\n",
                        "[CV 9/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500..\n",
                        "[CV 6/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.567 total time= 2.0min\n",
                        "[CV 10/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 7/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.598 total time= 1.9min\n",
                        "[CV 11/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 8/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.614 total time= 1.9min\n",
                        "[CV 12/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 9/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.605 total time= 1.9min\n",
                        "[CV 13/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 10/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.608 total time= 1.9min\n",
                        "[CV 14/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 11/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.591 total time= 1.9min\n",
                        "[CV 15/15; 16/30] START learning_rate=0.03, loss=exponential, n_estimators=1500.\n",
                        "[CV 12/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.584 total time= 2.0min\n",
                        "[CV 1/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 13/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.551 total time= 1.9min\n",
                        "[CV 2/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 14/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.590 total time= 1.9min\n",
                        "[CV 3/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 15/15; 16/30] END learning_rate=0.03, loss=exponential, n_estimators=1500;, score=0.634 total time= 1.9min\n",
                        "[CV 4/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 1/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.591 total time= 2.4min\n",
                        "[CV 5/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 2/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.546 total time= 2.5min\n",
                        "[CV 6/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 3/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.573 total time= 2.4min\n",
                        "[CV 7/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 4/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.581 total time= 2.4min\n",
                        "[CV 8/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 5/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.632 total time= 2.5min\n",
                        "[CV 9/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000..\n",
                        "[CV 6/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.531 total time= 2.4min\n",
                        "[CV 10/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 7/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.581 total time= 2.5min\n",
                        "[CV 11/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 8/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.597 total time= 2.4min\n",
                        "[CV 12/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 9/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.567 total time= 2.4min\n",
                        "[CV 13/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 10/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.577 total time= 2.4min\n",
                        "[CV 14/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 11/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.564 total time= 2.5min\n",
                        "[CV 15/15; 17/30] START learning_rate=0.03, loss=exponential, n_estimators=2000.\n",
                        "[CV 12/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.557 total time= 2.5min\n",
                        "[CV 1/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 13/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.529 total time= 2.4min\n",
                        "[CV 2/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 14/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.564 total time= 2.4min\n",
                        "[CV 3/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 15/15; 17/30] END learning_rate=0.03, loss=exponential, n_estimators=2000;, score=0.618 total time= 2.4min\n",
                        "[CV 4/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 1/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.558 total time= 3.4min\n",
                        "[CV 5/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 2/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.513 total time= 3.4min\n",
                        "[CV 6/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 3/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.531 total time= 3.4min\n",
                        "[CV 7/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 4/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.556 total time= 3.4min\n",
                        "[CV 8/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 5/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.601 total time= 3.5min\n",
                        "[CV 9/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000..\n",
                        "[CV 6/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.488 total time= 3.9min\n",
                        "[CV 10/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 7/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.547 total time= 4.2min\n",
                        "[CV 11/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 8/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.572 total time= 4.4min\n",
                        "[CV 12/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 9/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.549 total time= 5.9min\n",
                        "[CV 13/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 10/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.552 total time= 5.9min\n",
                        "[CV 14/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 11/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.539 total time= 5.6min\n",
                        "[CV 15/15; 18/30] START learning_rate=0.03, loss=exponential, n_estimators=3000.\n",
                        "[CV 12/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.524 total time= 5.3min\n",
                        "[CV 1/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 13/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.505 total time= 3.7min\n",
                        "[CV 2/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 14/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.515 total time= 3.3min\n",
                        "[CV 3/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 15/15; 18/30] END learning_rate=0.03, loss=exponential, n_estimators=3000;, score=0.603 total time= 3.4min\n",
                        "[CV 4/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 1/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.542 total time= 4.3min\n",
                        "[CV 5/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 2/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.499 total time= 4.3min\n",
                        "[CV 6/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 3/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.511 total time= 4.3min\n",
                        "[CV 7/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 4/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.535 total time= 4.2min\n",
                        "[CV 8/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 5/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.578 total time= 4.3min\n",
                        "[CV 9/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000..\n",
                        "[CV 6/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.474 total time= 4.3min\n",
                        "[CV 10/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 7/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.532 total time= 4.3min\n",
                        "[CV 11/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 8/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.567 total time= 4.2min\n",
                        "[CV 12/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 9/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.541 total time= 4.3min\n",
                        "[CV 13/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 10/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.527 total time= 4.3min\n",
                        "[CV 14/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 11/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.521 total time= 4.3min\n",
                        "[CV 15/15; 19/30] START learning_rate=0.03, loss=exponential, n_estimators=4000.\n",
                        "[CV 12/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.504 total time= 4.3min\n",
                        "[CV 1/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 13/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.497 total time= 4.3min\n",
                        "[CV 2/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 14/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.492 total time= 4.2min\n",
                        "[CV 3/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 15/15; 19/30] END learning_rate=0.03, loss=exponential, n_estimators=4000;, score=0.594 total time= 4.3min\n",
                        "[CV 4/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 1/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.532 total time= 5.1min\n",
                        "[CV 5/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 2/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.496 total time= 5.2min\n",
                        "[CV 6/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 3/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.495 total time= 5.1min\n",
                        "[CV 7/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 4/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.519 total time= 5.1min\n",
                        "[CV 8/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 5/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.564 total time= 5.1min\n",
                        "[CV 9/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000..\n",
                        "[CV 6/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.469 total time= 5.2min\n",
                        "[CV 10/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 7/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.523 total time= 5.1min\n",
                        "[CV 11/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 8/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.564 total time= 5.0min\n",
                        "[CV 12/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 9/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.534 total time= 5.1min\n",
                        "[CV 13/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 10/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.519 total time= 5.2min\n",
                        "[CV 14/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 11/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.518 total time= 5.2min\n",
                        "[CV 15/15; 20/30] START learning_rate=0.03, loss=exponential, n_estimators=5000.\n",
                        "[CV 12/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.489 total time= 5.2min\n",
                        "[CV 1/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 1/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.769 total time=  10.8s\n",
                        "[CV 2/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 2/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.758 total time=  10.9s\n",
                        "[CV 3/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 3/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.732 total time=  10.9s\n",
                        "[CV 4/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 4/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.693 total time=  10.9s\n",
                        "[CV 5/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 5/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.770 total time=  11.0s\n",
                        "[CV 6/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 6/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.736 total time=  10.9s\n",
                        "[CV 7/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 7/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.711 total time=  11.0s\n",
                        "[CV 8/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 8/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.759 total time=  11.1s\n",
                        "[CV 9/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100...\n",
                        "[CV 9/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.771 total time=  11.0s\n",
                        "[CV 10/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 13/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.486 total time= 5.1min\n",
                        "[CV 11/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 10/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.728 total time=  11.0s\n",
                        "[CV 12/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 11/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.755 total time=  11.0s\n",
                        "[CV 13/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 12/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.776 total time=  10.9s\n",
                        "[CV 14/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 13/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.740 total time=  10.8s\n",
                        "[CV 15/15; 21/30] START learning_rate=0.05, loss=exponential, n_estimators=100..\n",
                        "[CV 14/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.694 total time=  10.8s\n",
                        "[CV 1/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 15/15; 21/30] END learning_rate=0.05, loss=exponential, n_estimators=100;, score=0.726 total time=  10.9s\n",
                        "[CV 2/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 1/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.718 total time=  29.0s\n",
                        "[CV 3/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 2/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.685 total time=  29.3s\n",
                        "[CV 4/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 3/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.693 total time=  29.1s\n",
                        "[CV 5/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 14/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.481 total time= 5.1min\n",
                        "[CV 6/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 4/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.658 total time=  29.4s\n",
                        "[CV 7/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 5/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.725 total time=  28.7s\n",
                        "[CV 8/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 6/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.677 total time=  28.6s\n",
                        "[CV 9/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300...\n",
                        "[CV 7/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.675 total time=  28.5s\n",
                        "[CV 10/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.714 total time=  28.5s\n",
                        "[CV 11/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 9/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.711 total time=  28.6s\n",
                        "[CV 12/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 10/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.699 total time=  28.4s\n",
                        "[CV 13/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 15/15; 20/30] END learning_rate=0.03, loss=exponential, n_estimators=5000;, score=0.586 total time= 5.1min\n",
                        "[CV 14/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 11/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.716 total time=  28.5s\n",
                        "[CV 15/15; 22/30] START learning_rate=0.05, loss=exponential, n_estimators=300..\n",
                        "[CV 12/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.704 total time=  28.6s\n",
                        "[CV 1/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 13/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.677 total time=  28.6s\n",
                        "[CV 2/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 14/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.671 total time=  27.9s\n",
                        "[CV 3/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 15/15; 22/30] END learning_rate=0.05, loss=exponential, n_estimators=300;, score=0.695 total time=  28.0s\n",
                        "[CV 4/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 1/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.675 total time=  43.1s\n",
                        "[CV 5/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 2/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.629 total time=  43.3s\n",
                        "[CV 6/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 3/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.652 total time=  42.9s\n",
                        "[CV 7/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 4/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.625 total time=  43.1s\n",
                        "[CV 8/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 5/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.692 total time=  43.1s\n",
                        "[CV 9/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500...\n",
                        "[CV 6/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.632 total time=  42.8s\n",
                        "[CV 10/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 7/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.645 total time=  42.6s\n",
                        "[CV 11/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 8/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.671 total time=  43.1s\n",
                        "[CV 12/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 9/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.663 total time=  43.4s\n",
                        "[CV 13/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 10/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.660 total time=  43.3s\n",
                        "[CV 14/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 11/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.671 total time=  43.2s\n",
                        "[CV 15/15; 23/30] START learning_rate=0.05, loss=exponential, n_estimators=500..\n",
                        "[CV 12/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.642 total time=  43.8s\n",
                        "[CV 1/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 13/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.615 total time=  43.6s\n",
                        "[CV 2/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 14/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.637 total time=  43.4s\n",
                        "[CV 3/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 15/15; 23/30] END learning_rate=0.05, loss=exponential, n_estimators=500;, score=0.667 total time=  43.1s\n",
                        "[CV 4/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 1/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.629 total time= 1.0min\n",
                        "[CV 5/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 2/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.573 total time= 1.1min\n",
                        "[CV 6/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 3/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.607 total time= 1.0min\n",
                        "[CV 7/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 4/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.598 total time= 1.0min\n",
                        "[CV 8/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 5/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.665 total time= 1.0min\n",
                        "[CV 9/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800...\n",
                        "[CV 7/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.607 total time= 1.0min\n",
                        "[CV 10/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 6/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.588 total time= 1.0min\n",
                        "[CV 11/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 8/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.625 total time= 1.0min\n",
                        "[CV 12/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 9/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.618 total time= 1.0min\n",
                        "[CV 13/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 10/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.614 total time= 1.0min\n",
                        "[CV 14/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 11/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.613 total time= 1.0min\n",
                        "[CV 15/15; 24/30] START learning_rate=0.05, loss=exponential, n_estimators=800..\n",
                        "[CV 12/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.604 total time= 1.1min\n",
                        "[CV 1/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 13/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.562 total time= 1.0min\n",
                        "[CV 2/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 14/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.598 total time= 1.0min\n",
                        "[CV 3/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 15/15; 24/30] END learning_rate=0.05, loss=exponential, n_estimators=800;, score=0.641 total time= 1.0min\n",
                        "[CV 4/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 1/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.605 total time= 1.2min\n",
                        "[CV 5/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 2/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.561 total time= 1.3min\n",
                        "[CV 6/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 3/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.584 total time= 1.2min\n",
                        "[CV 7/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 4/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.587 total time= 1.2min\n",
                        "[CV 8/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 5/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.651 total time= 1.2min\n",
                        "[CV 9/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000..\n",
                        "[CV 6/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.550 total time= 1.2min\n",
                        "[CV 10/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 7/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.592 total time= 1.2min\n",
                        "[CV 11/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 8/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.615 total time= 1.2min\n",
                        "[CV 12/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 9/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.595 total time= 1.2min\n",
                        "[CV 13/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 10/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.592 total time= 1.3min\n",
                        "[CV 14/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 11/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.586 total time= 1.2min\n",
                        "[CV 15/15; 25/30] START learning_rate=0.05, loss=exponential, n_estimators=1000.\n",
                        "[CV 12/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.572 total time= 1.3min\n",
                        "[CV 1/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 13/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.543 total time= 1.3min\n",
                        "[CV 2/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 14/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.584 total time= 1.2min\n",
                        "[CV 3/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 15/15; 25/30] END learning_rate=0.05, loss=exponential, n_estimators=1000;, score=0.624 total time= 1.2min\n",
                        "[CV 4/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 1/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.572 total time= 1.7min\n",
                        "[CV 5/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 2/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.521 total time= 1.7min\n",
                        "[CV 6/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 3/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.547 total time= 1.7min\n",
                        "[CV 7/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 4/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.568 total time= 1.7min\n",
                        "[CV 8/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 5/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.617 total time= 1.7min\n",
                        "[CV 9/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500..\n",
                        "[CV 6/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.506 total time= 1.7min\n",
                        "[CV 10/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 7/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.566 total time= 1.7min\n",
                        "[CV 11/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 8/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.580 total time= 1.7min\n",
                        "[CV 12/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 9/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.564 total time= 1.7min\n",
                        "[CV 13/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 10/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.562 total time= 1.7min\n",
                        "[CV 14/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 11/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.552 total time= 1.7min\n",
                        "[CV 15/15; 26/30] START learning_rate=0.05, loss=exponential, n_estimators=1500.\n",
                        "[CV 12/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.538 total time= 1.7min\n",
                        "[CV 1/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 13/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.518 total time= 1.7min\n",
                        "[CV 2/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 14/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.535 total time= 1.7min\n",
                        "[CV 3/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 15/15; 26/30] END learning_rate=0.05, loss=exponential, n_estimators=1500;, score=0.606 total time= 1.7min\n",
                        "[CV 4/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 1/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.553 total time= 2.2min\n",
                        "[CV 5/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 2/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.514 total time= 2.2min\n",
                        "[CV 6/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 3/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.524 total time= 2.2min\n",
                        "[CV 7/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 4/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.543 total time= 2.1min\n",
                        "[CV 8/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 5/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.593 total time= 2.2min\n",
                        "[CV 9/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000..\n",
                        "[CV 6/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.478 total time= 2.2min\n",
                        "[CV 10/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 7/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.545 total time= 2.2min\n",
                        "[CV 11/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 8/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.573 total time= 2.2min\n",
                        "[CV 12/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 9/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.547 total time= 2.2min\n",
                        "[CV 13/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 10/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.540 total time= 2.2min\n",
                        "[CV 14/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 11/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.538 total time= 2.2min\n",
                        "[CV 15/15; 27/30] START learning_rate=0.05, loss=exponential, n_estimators=2000.\n",
                        "[CV 12/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.514 total time= 2.2min\n",
                        "[CV 1/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 13/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.502 total time= 2.2min\n",
                        "[CV 2/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 14/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.512 total time= 2.1min\n",
                        "[CV 3/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 15/15; 27/30] END learning_rate=0.05, loss=exponential, n_estimators=2000;, score=0.602 total time= 2.2min\n",
                        "[CV 4/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 1/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.528 total time= 3.1min\n",
                        "[CV 5/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 2/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.488 total time= 3.1min\n",
                        "[CV 6/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 3/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.495 total time= 3.1min\n",
                        "[CV 7/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 4/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.520 total time= 3.0min\n",
                        "[CV 8/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 5/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.567 total time= 3.1min\n",
                        "[CV 9/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000..\n",
                        "[CV 6/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.468 total time= 3.1min\n",
                        "[CV 10/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 7/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.524 total time= 3.1min\n",
                        "[CV 11/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 8/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.565 total time= 3.0min\n",
                        "[CV 12/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 9/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.535 total time= 3.1min\n",
                        "[CV 13/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 10/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.521 total time= 3.1min\n",
                        "[CV 14/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 11/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.513 total time= 3.1min\n",
                        "[CV 15/15; 28/30] START learning_rate=0.05, loss=exponential, n_estimators=3000.\n",
                        "[CV 12/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.488 total time= 3.1min\n",
                        "[CV 1/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 13/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.489 total time= 3.1min\n",
                        "[CV 2/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 14/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.479 total time= 3.0min\n",
                        "[CV 3/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 15/15; 28/30] END learning_rate=0.05, loss=exponential, n_estimators=3000;, score=0.586 total time= 3.1min\n",
                        "[CV 4/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 1/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.517 total time= 3.9min\n",
                        "[CV 5/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 2/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.486 total time= 4.0min\n",
                        "[CV 6/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 3/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.481 total time= 3.9min\n",
                        "[CV 7/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 4/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.500 total time= 3.9min\n",
                        "[CV 8/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 5/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.546 total time= 4.0min\n",
                        "[CV 9/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000..\n",
                        "[CV 6/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.459 total time= 4.0min\n",
                        "[CV 10/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 7/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.511 total time= 3.9min\n",
                        "[CV 11/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 8/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.558 total time= 3.9min\n",
                        "[CV 12/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 9/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.530 total time= 4.0min\n",
                        "[CV 13/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 10/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.493 total time= 4.0min\n",
                        "[CV 14/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 11/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.506 total time= 4.0min\n",
                        "[CV 15/15; 29/30] START learning_rate=0.05, loss=exponential, n_estimators=4000.\n",
                        "[CV 12/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.464 total time= 3.9min\n",
                        "[CV 1/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 13/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.476 total time= 4.0min\n",
                        "[CV 2/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 14/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.473 total time= 3.9min\n",
                        "[CV 3/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 15/15; 29/30] END learning_rate=0.05, loss=exponential, n_estimators=4000;, score=0.574 total time= 4.0min\n",
                        "[CV 4/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 1/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.512 total time= 4.8min\n",
                        "[CV 5/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 2/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.478 total time= 4.8min\n",
                        "[CV 6/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 3/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.472 total time= 4.8min\n",
                        "[CV 7/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 4/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.500 total time= 4.7min\n",
                        "[CV 8/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 5/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.536 total time= 4.8min\n",
                        "[CV 9/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000..\n",
                        "[CV 6/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.455 total time= 4.8min\n",
                        "[CV 10/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 7/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.501 total time= 4.8min\n",
                        "[CV 11/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 8/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.561 total time= 4.7min\n",
                        "[CV 12/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 9/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.528 total time= 4.8min\n",
                        "[CV 13/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 10/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.484 total time= 4.8min\n",
                        "[CV 14/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 11/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.500 total time= 4.8min\n",
                        "[CV 15/15; 30/30] START learning_rate=0.05, loss=exponential, n_estimators=5000.\n",
                        "[CV 12/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.458 total time= 4.8min\n",
                        "[CV 13/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.478 total time= 4.2min\n",
                        "[CV 14/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.476 total time= 3.9min\n",
                        "[CV 15/15; 30/30] END learning_rate=0.05, loss=exponential, n_estimators=5000;, score=0.572 total time= 3.3min\n",
                        "Best: 0.7467177878962168 using {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 100, 'scoring': 'r2', 'best_score': 0.7467177878962168, 'n_splits': 5, 'n_repeats': 3} \n",
                        "\n",
                        "0.7467177878962168 (0.027048203176315535) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 100, 'scoring': 'r2', 'best_score': 0.7467177878962168, 'n_splits': 5, 'n_repeats': 3} \n",
                        "\n",
                        "0.7452228916675276 (0.02709135934998789) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.7416876845205673 (0.025563072699416864) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.7313113785269373 (0.023427244471739172) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.7216397558967823 (0.022081804822116132) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.6946226721999551 (0.01979207436099022) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.6709855991435771 (0.01994051147524863) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.6348974392135655 (0.022674222750938586) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.6091141711265242 (0.025080286915629597) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.5883221776643413 (0.026560143386493068) with: {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n",
                        "0.7444238088515859 (0.02686904952004955) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.7263980722738984 (0.022881358146849207) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.6942931955398935 (0.019762656292727988) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.6555443345028802 (0.020945209345376834) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.6360719393916326 (0.023034317044019793) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.5970746550053998 (0.02528897264700506) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.5739082327348867 (0.027575071626142884) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.5435550192389605 (0.031684383012596205) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.5275651498806709 (0.03229395487447564) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.5183060741553737 (0.032627229869744485) with: {'learning_rate': 0.03, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n",
                        "0.7411656171087824 (0.026352693613179545) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.6944473018052596 (0.019420655977061264) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.6517946385934085 (0.02116004825169668) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.6094742141226918 (0.0248091678623131) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.5893987268513812 (0.026899727301924938) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.5568983595468182 (0.029945996064075015) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.5385865014181248 (0.032264342036008815) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.5176284254803031 (0.03349182280310313) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.5048270310036826 (0.03342330701094762) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.5007713932493335 (0.034137311125211636) with: {'learning_rate': 0.05, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'learning_rate': 0.01,\n",
                            " 'loss': 'exponential',\n",
                            " 'n_estimators': 100,\n",
                            " 'scoring': 'r2',\n",
                            " 'best_score': 0.7467177878962168,\n",
                            " 'n_splits': 5,\n",
                            " 'n_repeats': 3}"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "grid_search_optimization(X,y,\n",
                "                            n_estimators_v,\n",
                "                            learning_rate_v,\n",
                "                            scoring_metric=\"r2\",\n",
                "                            loss_functions_list=loss_function_v,\n",
                "                            n_cores = -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6a229a7624aaca0bb64305d3a84f8aa11ea5a7132c8c99f127f8b64a260fdc5c"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit (conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
