{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(5394, 85)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>__time_to_tca</th>\n",
                            "      <th>MISS_DISTANCE</th>\n",
                            "      <th>RELATIVE_SPEED</th>\n",
                            "      <th>RELATIVE_POSITION_R</th>\n",
                            "      <th>RELATIVE_POSITION_T</th>\n",
                            "      <th>RELATIVE_POSITION_N</th>\n",
                            "      <th>RELATIVE_VELOCITY_R</th>\n",
                            "      <th>RELATIVE_VELOCITY_T</th>\n",
                            "      <th>RELATIVE_VELOCITY_N</th>\n",
                            "      <th>COLLISSION_PROBABILITY</th>\n",
                            "      <th>...</th>\n",
                            "      <th>OBJECT2_CORR_CNDOT_TDOT</th>\n",
                            "      <th>PC_trend_1</th>\n",
                            "      <th>PC_trend_3</th>\n",
                            "      <th>PC_gradient_1</th>\n",
                            "      <th>PC_gradient_3</th>\n",
                            "      <th>MD_trend_1</th>\n",
                            "      <th>MD_trend_3</th>\n",
                            "      <th>MD_gradient_1</th>\n",
                            "      <th>MD_gradient_3</th>\n",
                            "      <th>TARGET_PC</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>5.775947</td>\n",
                            "      <td>568.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-20.9</td>\n",
                            "      <td>-562.8</td>\n",
                            "      <td>-75.9</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-5.415895</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.054742</td>\n",
                            "      <td>0.226170</td>\n",
                            "      <td>0.773872</td>\n",
                            "      <td>0.652610</td>\n",
                            "      <td>0.763062</td>\n",
                            "      <td>-123.0</td>\n",
                            "      <td>144.0</td>\n",
                            "      <td>-354.914301</td>\n",
                            "      <td>141.988456</td>\n",
                            "      <td>-5.345246</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>5.420762</td>\n",
                            "      <td>611.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-19.9</td>\n",
                            "      <td>-605.4</td>\n",
                            "      <td>-81.8</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-5.345246</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.029148</td>\n",
                            "      <td>0.070649</td>\n",
                            "      <td>0.237282</td>\n",
                            "      <td>0.198907</td>\n",
                            "      <td>0.234313</td>\n",
                            "      <td>43.0</td>\n",
                            "      <td>50.0</td>\n",
                            "      <td>121.063636</td>\n",
                            "      <td>49.374243</td>\n",
                            "      <td>-4.792366</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>5.119489</td>\n",
                            "      <td>576.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>-9.6</td>\n",
                            "      <td>-571.2</td>\n",
                            "      <td>-77.4</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.792366</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.030920</td>\n",
                            "      <td>0.552880</td>\n",
                            "      <td>0.849700</td>\n",
                            "      <td>1.835148</td>\n",
                            "      <td>0.847141</td>\n",
                            "      <td>-35.0</td>\n",
                            "      <td>-115.0</td>\n",
                            "      <td>-116.173757</td>\n",
                            "      <td>-114.653689</td>\n",
                            "      <td>-4.208450</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4.750068</td>\n",
                            "      <td>328.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>2.7</td>\n",
                            "      <td>-325.3</td>\n",
                            "      <td>-43.7</td>\n",
                            "      <td>0.5</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.208450</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.104064</td>\n",
                            "      <td>0.583916</td>\n",
                            "      <td>1.207445</td>\n",
                            "      <td>1.580622</td>\n",
                            "      <td>1.176985</td>\n",
                            "      <td>-248.0</td>\n",
                            "      <td>-240.0</td>\n",
                            "      <td>-671.319754</td>\n",
                            "      <td>-233.945596</td>\n",
                            "      <td>-4.049879</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>4.087221</td>\n",
                            "      <td>56.0</td>\n",
                            "      <td>2001.0</td>\n",
                            "      <td>9.2</td>\n",
                            "      <td>-55.1</td>\n",
                            "      <td>-7.3</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>-268.6</td>\n",
                            "      <td>1983.8</td>\n",
                            "      <td>-4.049879</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-0.117181</td>\n",
                            "      <td>0.158571</td>\n",
                            "      <td>1.295367</td>\n",
                            "      <td>0.239227</td>\n",
                            "      <td>0.971374</td>\n",
                            "      <td>-272.0</td>\n",
                            "      <td>-555.0</td>\n",
                            "      <td>-410.351242</td>\n",
                            "      <td>-416.185112</td>\n",
                            "      <td>-5.289798</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows Ã— 85 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   __time_to_tca  MISS_DISTANCE  RELATIVE_SPEED  RELATIVE_POSITION_R  \\\n",
                            "0       5.775947          568.0          2001.0                -20.9   \n",
                            "1       5.420762          611.0          2001.0                -19.9   \n",
                            "2       5.119489          576.0          2001.0                 -9.6   \n",
                            "3       4.750068          328.0          2001.0                  2.7   \n",
                            "4       4.087221           56.0          2001.0                  9.2   \n",
                            "\n",
                            "   RELATIVE_POSITION_T  RELATIVE_POSITION_N  RELATIVE_VELOCITY_R  \\\n",
                            "0               -562.8                -75.9                  0.8   \n",
                            "1               -605.4                -81.8                  0.8   \n",
                            "2               -571.2                -77.4                  0.8   \n",
                            "3               -325.3                -43.7                  0.5   \n",
                            "4                -55.1                 -7.3                  0.2   \n",
                            "\n",
                            "   RELATIVE_VELOCITY_T  RELATIVE_VELOCITY_N  COLLISSION_PROBABILITY  ...  \\\n",
                            "0               -268.6               1983.8               -5.415895  ...   \n",
                            "1               -268.6               1983.8               -5.345246  ...   \n",
                            "2               -268.6               1983.8               -4.792366  ...   \n",
                            "3               -268.6               1983.8               -4.208450  ...   \n",
                            "4               -268.6               1983.8               -4.049879  ...   \n",
                            "\n",
                            "   OBJECT2_CORR_CNDOT_TDOT  PC_trend_1  PC_trend_3  PC_gradient_1  \\\n",
                            "0                -0.054742    0.226170    0.773872       0.652610   \n",
                            "1                 0.029148    0.070649    0.237282       0.198907   \n",
                            "2                -0.030920    0.552880    0.849700       1.835148   \n",
                            "3                -0.104064    0.583916    1.207445       1.580622   \n",
                            "4                -0.117181    0.158571    1.295367       0.239227   \n",
                            "\n",
                            "   PC_gradient_3  MD_trend_1  MD_trend_3  MD_gradient_1  MD_gradient_3  \\\n",
                            "0       0.763062      -123.0       144.0    -354.914301     141.988456   \n",
                            "1       0.234313        43.0        50.0     121.063636      49.374243   \n",
                            "2       0.847141       -35.0      -115.0    -116.173757    -114.653689   \n",
                            "3       1.176985      -248.0      -240.0    -671.319754    -233.945596   \n",
                            "4       0.971374      -272.0      -555.0    -410.351242    -416.185112   \n",
                            "\n",
                            "   TARGET_PC  \n",
                            "0  -5.345246  \n",
                            "1  -4.792366  \n",
                            "2  -4.208450  \n",
                            "3  -4.049879  \n",
                            "4  -5.289798  \n",
                            "\n",
                            "[5 rows x 85 columns]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#./dataframe/df_only_risky_events.pkl\n",
                "#data=pd.read_pickle(\"dataframe/_PRUEBA_df_20211225_143242.pkl\") #dataframe full 2022\n",
                "data=pd.read_pickle(\"dataframe/_PRUEBA_df_filtered_20220115_112153.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test = train_test_split(data, test_size=0.30, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train dataframe dimension 3775 x 85\n",
                        "Test dataframe dimension 1619 x 85\n"
                    ]
                }
            ],
            "source": [
                "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
                "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "columnt_to_predict_name=\"TARGET_PC\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "Y_train = train[columnt_to_predict_name]\n",
                "X_train= train.drop([columnt_to_predict_name], axis=1)\n",
                "Y_test = test[columnt_to_predict_name]\n",
                "X_test= test.drop([columnt_to_predict_name], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import RepeatedKFold\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.ensemble import AdaBoostRegressor\n",
                "import datetime as dt\n",
                "import pickle\n",
                "\n",
                "\n",
                "def grid_search_optimization(\n",
                "    X,\n",
                "    y,\n",
                "    n_estimators_list=[10, 50],\n",
                "    learning_rate_list=[0.0001, 0.001],\n",
                "    loss_functions_list = [\"linear\"],\n",
                "    scoring_metric=\"r2\",\n",
                "    n_splits_for_cv = 5,\n",
                "    n_repeats_for_cv = 3,\n",
                "    n_cores = -1\n",
                "):\n",
                "    \"\"\"Computes the optimal values for the LGBM model\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    X : dataframe\n",
                "        Train dataset\n",
                "    y : target dataframe\n",
                "        Values to be predicted\n",
                "    n_estimators_list: list\n",
                "        List of n_estimators values for grid search\n",
                "    learning_rate_list: list\n",
                "        List of learning_rate values for grid search\n",
                "    scoring_metric: \n",
                "        Scoring metrics from sci-kit learn default r2\n",
                "    n_splits_for_cv:\n",
                "        Number of splits for K Fold cross validation\n",
                "    n_repeats_for_cv:\n",
                "        Number of repetition for cross validation\n",
                "    n_cores: int\n",
                "        Number of CPU cores for computation. Default -1 = all\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    dictionary\n",
                "        Optimized values\n",
                "    \"\"\"\n",
                "    # define the model with default hyperparameters\n",
                "    model = AdaBoostRegressor()\n",
                "    # define the grid of values to search\n",
                "    grid = dict()\n",
                "    grid['n_estimators'] = n_estimators_list\n",
                "    grid['learning_rate'] = learning_rate_list\n",
                "    grid['loss'] = loss_functions_list\n",
                "    # define the evaluation procedure\n",
                "    cv = RepeatedKFold(n_splits=n_splits_for_cv, n_repeats=n_repeats_for_cv, random_state=1)\n",
                "    # define the grid search procedure\n",
                "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs= n_cores, cv=cv, scoring=scoring_metric,verbose=10)\n",
                "\n",
                "    # execute the grid search\n",
                "    grid_result = grid_search.fit(X, y)\n",
                "\n",
                "    # summarize the best score and configuration\n",
                "    now=dt.datetime.now()\n",
                "    filename1=\"./opt_parameters_ada_boost/{}_{}_gs_opt_param.pkl\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    filename2=\"./opt_parameters_ada_boost/{}_gs_full_run.txt\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    with open(filename1, \"wb\") as optimal_parameters_logger:\n",
                "        output_dict = grid_result.best_params_\n",
                "        output_dict[\"scoring\"] = scoring_metric\n",
                "        output_dict[\"best_score\"] = grid_result.best_score_\n",
                "        output_dict[\"n_splits\"] = n_splits_for_cv\n",
                "        output_dict[\"n_repeats\"] = n_repeats_for_cv\n",
                "        pickle.dump(output_dict, optimal_parameters_logger)\n",
                "        optimal_parameters_logger.close()\n",
                "    with open(filename2, \"a\") as results_logger:\n",
                "        output_1 = \"Best: {} using {} \\n\".format(grid_result.best_score_, grid_result.best_params_)\n",
                "        print(output_1)\n",
                "        results_logger.write(output_1)\n",
                "        # summarize all scores that were evaluated\n",
                "        means = grid_result.cv_results_['mean_test_score']\n",
                "        stds = grid_result.cv_results_['std_test_score']\n",
                "        params = grid_result.cv_results_['params']\n",
                "        for mean, stdev, param in zip(means, stds, params):\n",
                "            output_2 = \"{} ({}) with: {} \\n\".format(mean, stdev, param)\n",
                "            print(output_2)\n",
                "            results_logger.write(output_2)\n",
                "        results_logger.close()\n",
                "    return output_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_estimators_v = [100,300,500,800,1000,1500,2000,3000,4000,5000]\n",
                "learning_rate_v=[0.001,0.002,0.003,0.005]\n",
                "#n_estimators_v = [100,300,500]\n",
                "#learning_rate_v=[0.01]\n",
                "loss_function_v = [\"exponential\"]\n",
                "#regression_metrics=[\"neg_root_mean_squared_error\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 15 folds for each of 40 candidates, totalling 600 fits\n",
                        "[CV 1/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 2/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 3/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 4/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 4/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.696 total time=  10.6s\n",
                        "[CV 5/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 3/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.729 total time=  11.4s\n",
                        "[CV 6/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 2/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.766 total time=  11.9s\n",
                        "[CV 7/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 1/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.771 total time=  12.4s\n",
                        "[CV 8/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 5/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.780 total time=  11.2s\n",
                        "[CV 9/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100...\n",
                        "[CV 8/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.764 total time=  10.5s\n",
                        "[CV 10/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 6/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.738 total time=  11.4s\n",
                        "[CV 11/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 7/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.723 total time=  12.3s\n",
                        "[CV 12/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 9/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.780 total time=  11.9s\n",
                        "[CV 13/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 11/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.760 total time=  11.8s\n",
                        "[CV 14/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 10/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.735 total time=  12.4s\n",
                        "[CV 15/15; 1/40] START learning_rate=0.001, loss=exponential, n_estimators=100..\n",
                        "[CV 12/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.791 total time=  12.6s\n",
                        "[CV 1/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 15/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.720 total time=  11.2s\n",
                        "[CV 2/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 13/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.744 total time=  12.4s\n",
                        "[CV 3/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 14/15; 1/40] END learning_rate=0.001, loss=exponential, n_estimators=100;, score=0.707 total time=  12.5s\n",
                        "[CV 4/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 1/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.773 total time=  35.6s\n",
                        "[CV 5/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 4/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.698 total time=  34.6s\n",
                        "[CV 6/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 2/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.765 total time=  35.9s\n",
                        "[CV 7/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 3/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.730 total time=  36.6s\n",
                        "[CV 8/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 5/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.779 total time=  34.2s\n",
                        "[CV 9/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300...\n",
                        "[CV 6/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.737 total time=  35.8s\n",
                        "[CV 10/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 7/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.726 total time=  36.6s\n",
                        "[CV 11/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.764 total time=  36.6s\n",
                        "[CV 12/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 9/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.778 total time=  37.7s\n",
                        "[CV 13/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 10/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.735 total time=  38.5s\n",
                        "[CV 14/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 11/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.764 total time=  38.0s\n",
                        "[CV 15/15; 2/40] START learning_rate=0.001, loss=exponential, n_estimators=300..\n",
                        "[CV 12/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.793 total time=  40.2s\n",
                        "[CV 1/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 13/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.744 total time=  43.0s\n",
                        "[CV 2/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 14/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.705 total time=  38.1s\n",
                        "[CV 3/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 15/15; 2/40] END learning_rate=0.001, loss=exponential, n_estimators=300;, score=0.722 total time=  39.5s\n",
                        "[CV 4/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 1/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.771 total time= 1.1min\n",
                        "[CV 5/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 2/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.765 total time= 1.0min\n",
                        "[CV 6/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 3/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.731 total time= 1.1min\n",
                        "[CV 7/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 4/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.699 total time= 1.1min\n",
                        "[CV 8/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 5/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.779 total time= 1.1min\n",
                        "[CV 9/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500...\n",
                        "[CV 6/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.737 total time= 1.1min\n",
                        "[CV 10/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 7/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.727 total time= 1.1min\n",
                        "[CV 11/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 8/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.762 total time= 1.1min\n",
                        "[CV 12/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 9/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.778 total time= 1.1min\n",
                        "[CV 13/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 10/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.734 total time= 1.1min\n",
                        "[CV 14/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 11/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.764 total time= 1.1min\n",
                        "[CV 15/15; 3/40] START learning_rate=0.001, loss=exponential, n_estimators=500..\n",
                        "[CV 12/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.792 total time= 1.1min\n",
                        "[CV 1/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 13/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.745 total time= 1.2min\n",
                        "[CV 2/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 14/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.705 total time= 1.1min\n",
                        "[CV 3/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 15/15; 3/40] END learning_rate=0.001, loss=exponential, n_estimators=500;, score=0.721 total time= 1.1min\n",
                        "[CV 4/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 1/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.771 total time= 1.8min\n",
                        "[CV 5/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 2/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.766 total time= 1.8min\n",
                        "[CV 6/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 3/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.731 total time= 1.9min\n",
                        "[CV 7/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 4/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.697 total time= 1.8min\n",
                        "[CV 8/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 5/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.780 total time= 1.7min\n",
                        "[CV 9/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800...\n",
                        "[CV 6/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.737 total time= 1.8min\n",
                        "[CV 10/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 7/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.727 total time= 1.8min\n",
                        "[CV 11/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 8/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.762 total time= 1.8min\n",
                        "[CV 12/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 9/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.776 total time= 1.8min\n",
                        "[CV 13/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 10/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.736 total time= 1.9min\n",
                        "[CV 14/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 11/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.763 total time= 1.9min\n",
                        "[CV 15/15; 4/40] START learning_rate=0.001, loss=exponential, n_estimators=800..\n",
                        "[CV 12/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.791 total time= 1.9min\n",
                        "[CV 1/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 13/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.745 total time= 1.9min\n",
                        "[CV 2/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 14/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.705 total time= 1.9min\n",
                        "[CV 3/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 15/15; 4/40] END learning_rate=0.001, loss=exponential, n_estimators=800;, score=0.722 total time= 1.8min\n",
                        "[CV 4/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 1/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.769 total time= 2.3min\n",
                        "[CV 5/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 2/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.765 total time= 2.3min\n",
                        "[CV 6/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 3/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.731 total time= 2.3min\n",
                        "[CV 7/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 4/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.699 total time= 2.2min\n",
                        "[CV 8/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 5/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.780 total time= 2.3min\n",
                        "[CV 9/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000..\n",
                        "[CV 6/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.737 total time= 2.3min\n",
                        "[CV 10/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 7/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.726 total time= 2.3min\n",
                        "[CV 11/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 8/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.762 total time= 2.3min\n",
                        "[CV 12/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 9/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.775 total time= 2.3min\n",
                        "[CV 13/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 10/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.735 total time= 2.4min\n",
                        "[CV 14/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 11/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.763 total time= 2.4min\n",
                        "[CV 15/15; 5/40] START learning_rate=0.001, loss=exponential, n_estimators=1000.\n",
                        "[CV 12/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.790 total time= 2.3min\n",
                        "[CV 1/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 13/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.746 total time= 2.3min\n",
                        "[CV 2/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 14/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.704 total time= 2.6min\n",
                        "[CV 3/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 15/15; 5/40] END learning_rate=0.001, loss=exponential, n_estimators=1000;, score=0.723 total time= 2.5min\n",
                        "[CV 4/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 1/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.769 total time= 3.7min\n",
                        "[CV 5/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 2/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.767 total time= 3.6min\n",
                        "[CV 6/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 3/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.731 total time= 3.4min\n",
                        "[CV 7/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 4/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.699 total time= 3.2min\n",
                        "[CV 8/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 5/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.779 total time= 3.4min\n",
                        "[CV 9/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500..\n",
                        "[CV 6/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.736 total time= 3.4min\n",
                        "[CV 10/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 7/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.725 total time= 3.5min\n",
                        "[CV 11/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 8/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.761 total time= 3.5min\n",
                        "[CV 12/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 9/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.773 total time= 3.7min\n",
                        "[CV 13/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 10/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.734 total time= 3.7min\n",
                        "[CV 14/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 11/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.763 total time= 3.6min\n",
                        "[CV 15/15; 6/40] START learning_rate=0.001, loss=exponential, n_estimators=1500.\n",
                        "[CV 12/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.790 total time= 3.5min\n",
                        "[CV 1/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 13/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.745 total time= 3.2min\n",
                        "[CV 2/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 14/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.704 total time= 3.2min\n",
                        "[CV 3/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 15/15; 6/40] END learning_rate=0.001, loss=exponential, n_estimators=1500;, score=0.723 total time= 3.4min\n",
                        "[CV 4/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 1/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.771 total time= 4.4min\n",
                        "[CV 5/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 2/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.767 total time= 4.5min\n",
                        "[CV 6/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 3/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.731 total time= 4.7min\n",
                        "[CV 7/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 4/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.698 total time= 4.6min\n",
                        "[CV 8/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 5/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.777 total time= 4.4min\n",
                        "[CV 9/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000..\n",
                        "[CV 6/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.736 total time= 4.1min\n",
                        "[CV 10/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 7/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.724 total time= 3.8min\n",
                        "[CV 11/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 8/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.761 total time= 3.7min\n",
                        "[CV 12/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 9/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.771 total time= 3.8min\n",
                        "[CV 13/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 10/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.733 total time= 3.8min\n",
                        "[CV 14/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 11/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.762 total time= 3.9min\n",
                        "[CV 15/15; 7/40] START learning_rate=0.001, loss=exponential, n_estimators=2000.\n",
                        "[CV 12/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.789 total time= 4.0min\n",
                        "[CV 1/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 13/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.743 total time= 4.0min\n",
                        "[CV 2/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 14/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.704 total time= 3.9min\n",
                        "[CV 3/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 15/15; 7/40] END learning_rate=0.001, loss=exponential, n_estimators=2000;, score=0.724 total time= 3.9min\n",
                        "[CV 4/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 1/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.771 total time= 5.7min\n",
                        "[CV 5/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 2/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.765 total time= 5.6min\n",
                        "[CV 6/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 3/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.731 total time= 5.5min\n",
                        "[CV 7/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 4/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.696 total time= 5.6min\n",
                        "[CV 8/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 5/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.775 total time= 5.7min\n",
                        "[CV 9/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000..\n",
                        "[CV 6/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.739 total time= 5.8min\n",
                        "[CV 10/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 7/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.719 total time= 5.7min\n",
                        "[CV 11/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 8/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.761 total time= 5.7min\n",
                        "[CV 12/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 9/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.771 total time= 5.6min\n",
                        "[CV 13/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 10/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.732 total time= 5.7min\n",
                        "[CV 14/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 11/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.760 total time= 5.6min\n",
                        "[CV 15/15; 8/40] START learning_rate=0.001, loss=exponential, n_estimators=3000.\n",
                        "[CV 12/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.787 total time= 5.7min\n",
                        "[CV 1/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 13/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.741 total time= 5.7min\n",
                        "[CV 2/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 14/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.701 total time= 5.6min\n",
                        "[CV 3/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 15/15; 8/40] END learning_rate=0.001, loss=exponential, n_estimators=3000;, score=0.728 total time= 5.6min\n",
                        "[CV 4/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 1/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.771 total time= 8.0min\n",
                        "[CV 5/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 2/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.762 total time= 8.0min\n",
                        "[CV 6/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 3/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.731 total time= 8.0min\n",
                        "[CV 7/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 4/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.693 total time= 8.2min\n",
                        "[CV 8/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 5/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.773 total time= 8.0min\n",
                        "[CV 9/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000..\n",
                        "[CV 6/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.739 total time= 8.0min\n",
                        "[CV 10/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 7/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.714 total time= 8.1min\n",
                        "[CV 11/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 8/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.759 total time= 8.0min\n",
                        "[CV 12/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 9/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.771 total time= 8.1min\n",
                        "[CV 13/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 10/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.730 total time= 8.3min\n",
                        "[CV 14/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 11/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.758 total time= 8.3min\n",
                        "[CV 15/15; 9/40] START learning_rate=0.001, loss=exponential, n_estimators=4000.\n",
                        "[CV 12/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.784 total time= 8.2min\n",
                        "[CV 1/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 13/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.742 total time= 8.3min\n",
                        "[CV 2/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 14/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.698 total time= 8.5min\n",
                        "[CV 3/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 15/15; 9/40] END learning_rate=0.001, loss=exponential, n_estimators=4000;, score=0.728 total time= 8.5min\n",
                        "[CV 4/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 1/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.769 total time=10.7min\n",
                        "[CV 5/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 2/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.758 total time=10.8min\n",
                        "[CV 6/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 3/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.731 total time=10.7min\n",
                        "[CV 7/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 4/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.693 total time=10.7min\n",
                        "[CV 8/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 5/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.771 total time=10.8min\n",
                        "[CV 9/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000.\n",
                        "[CV 6/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.737 total time=10.9min\n",
                        "[CV 10/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 7/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.711 total time=11.2min\n",
                        "[CV 11/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 8/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.759 total time=11.0min\n",
                        "[CV 12/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 9/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.768 total time=10.4min\n",
                        "[CV 13/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 10/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.728 total time= 9.9min\n",
                        "[CV 14/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 11/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.756 total time= 9.1min\n",
                        "[CV 15/15; 10/40] START learning_rate=0.001, loss=exponential, n_estimators=5000\n",
                        "[CV 12/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.778 total time= 9.0min\n",
                        "[CV 1/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 1/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.772 total time=  11.0s\n",
                        "[CV 2/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 2/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.766 total time=  11.8s\n",
                        "[CV 3/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 3/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.729 total time=  11.2s\n",
                        "[CV 4/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 4/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.697 total time=  11.1s\n",
                        "[CV 5/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 5/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.781 total time=  10.8s\n",
                        "[CV 6/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 6/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.737 total time=  11.2s\n",
                        "[CV 7/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 7/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.722 total time=  10.6s\n",
                        "[CV 8/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 8/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.763 total time=  11.5s\n",
                        "[CV 9/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100..\n",
                        "[CV 9/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.779 total time=  10.7s\n",
                        "[CV 10/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 10/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.734 total time=  11.9s\n",
                        "[CV 11/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 11/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.764 total time=  11.7s\n",
                        "[CV 12/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 12/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.792 total time=  11.7s\n",
                        "[CV 13/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 13/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.742 total time=  10.7s\n",
                        "[CV 14/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 13/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.740 total time= 9.0min\n",
                        "[CV 15/15; 11/40] START learning_rate=0.002, loss=exponential, n_estimators=100.\n",
                        "[CV 14/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.705 total time=  11.5s\n",
                        "[CV 1/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 15/15; 11/40] END learning_rate=0.002, loss=exponential, n_estimators=100;, score=0.721 total time=  11.5s\n",
                        "[CV 2/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 1/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.772 total time=  33.4s\n",
                        "[CV 3/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 2/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.765 total time=  33.6s\n",
                        "[CV 4/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 3/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.731 total time=  32.6s\n",
                        "[CV 5/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 4/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.699 total time=  33.5s\n",
                        "[CV 6/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 5/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.779 total time=  33.2s\n",
                        "[CV 7/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 6/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.738 total time=  34.0s\n",
                        "[CV 8/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 7/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.727 total time=  32.9s\n",
                        "[CV 9/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.761 total time=  33.0s\n",
                        "[CV 10/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 9/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.777 total time=  32.2s\n",
                        "[CV 11/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 14/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.698 total time= 8.9min\n",
                        "[CV 12/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 10/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.736 total time=  31.6s\n",
                        "[CV 13/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 11/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.762 total time=  33.2s\n",
                        "[CV 14/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 12/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.792 total time=  33.2s\n",
                        "[CV 15/15; 12/40] START learning_rate=0.002, loss=exponential, n_estimators=300.\n",
                        "[CV 13/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.746 total time=  32.5s\n",
                        "[CV 1/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 14/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.705 total time=  33.4s\n",
                        "[CV 2/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 12/40] END learning_rate=0.002, loss=exponential, n_estimators=300;, score=0.722 total time=  33.7s\n",
                        "[CV 3/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 1/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.770 total time=  55.4s\n",
                        "[CV 4/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 2/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.767 total time=  55.1s\n",
                        "[CV 5/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 3/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.732 total time=  56.1s\n",
                        "[CV 6/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 4/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.698 total time=  54.4s\n",
                        "[CV 7/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 10/40] END learning_rate=0.001, loss=exponential, n_estimators=5000;, score=0.727 total time= 9.1min\n",
                        "[CV 8/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 5/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.779 total time=  53.7s\n",
                        "[CV 9/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500..\n",
                        "[CV 6/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.737 total time=  56.0s\n",
                        "[CV 10/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 7/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.724 total time=  55.5s\n",
                        "[CV 11/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 9/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.775 total time=  54.8s\n",
                        "[CV 12/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 8/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.761 total time=  56.0s\n",
                        "[CV 13/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 10/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.734 total time=  56.3s\n",
                        "[CV 14/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 11/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.763 total time=  55.3s\n",
                        "[CV 15/15; 13/40] START learning_rate=0.002, loss=exponential, n_estimators=500.\n",
                        "[CV 13/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.747 total time=  54.6s\n",
                        "[CV 1/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 12/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.791 total time=  56.4s\n",
                        "[CV 2/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 14/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.706 total time=  54.7s\n",
                        "[CV 3/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 15/15; 13/40] END learning_rate=0.002, loss=exponential, n_estimators=500;, score=0.722 total time=133.5min\n",
                        "[CV 4/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 2/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.766 total time=134.2min\n",
                        "[CV 5/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 1/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.770 total time=134.2min\n",
                        "[CV 6/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 3/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.731 total time=134.1min\n",
                        "[CV 7/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 4/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.699 total time= 1.5min\n",
                        "[CV 8/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 5/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.779 total time= 1.5min\n",
                        "[CV 9/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800..\n",
                        "[CV 6/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.736 total time= 1.6min\n",
                        "[CV 10/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 7/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.727 total time= 1.6min\n",
                        "[CV 11/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 8/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.762 total time= 1.5min\n",
                        "[CV 12/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 9/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.771 total time= 1.5min\n",
                        "[CV 13/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 10/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.734 total time= 1.5min\n",
                        "[CV 14/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 11/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.762 total time= 1.5min\n",
                        "[CV 15/15; 14/40] START learning_rate=0.002, loss=exponential, n_estimators=800.\n",
                        "[CV 12/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.789 total time= 1.5min\n",
                        "[CV 1/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 13/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.744 total time= 1.5min\n",
                        "[CV 2/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 14/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.704 total time= 1.6min\n",
                        "[CV 3/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 15/15; 14/40] END learning_rate=0.002, loss=exponential, n_estimators=800;, score=0.722 total time= 1.6min\n",
                        "[CV 4/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 1/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.771 total time= 2.0min\n",
                        "[CV 5/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 2/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.766 total time= 2.1min\n",
                        "[CV 6/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 3/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.731 total time= 2.1min\n",
                        "[CV 7/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 4/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.698 total time= 2.0min\n",
                        "[CV 8/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 5/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.777 total time= 1.9min\n",
                        "[CV 9/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000.\n",
                        "[CV 6/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.736 total time= 1.6min\n",
                        "[CV 10/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 7/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.724 total time= 1.6min\n",
                        "[CV 11/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 8/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.761 total time= 1.6min\n",
                        "[CV 12/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 9/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.770 total time= 1.7min\n",
                        "[CV 13/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 10/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.733 total time= 1.8min\n",
                        "[CV 14/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 12/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.788 total time= 1.8min\n",
                        "[CV 15/15; 15/40] START learning_rate=0.002, loss=exponential, n_estimators=1000\n",
                        "[CV 11/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.762 total time= 1.8min\n",
                        "[CV 1/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 13/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.743 total time= 1.8min\n",
                        "[CV 2/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 14/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.704 total time= 1.8min\n",
                        "[CV 3/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 15/15; 15/40] END learning_rate=0.002, loss=exponential, n_estimators=1000;, score=0.722 total time= 1.8min\n",
                        "[CV 4/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 1/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.771 total time= 2.7min\n",
                        "[CV 5/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 2/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.764 total time= 2.7min\n",
                        "[CV 6/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 3/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.730 total time= 2.7min\n",
                        "[CV 7/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 4/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.696 total time= 2.7min\n",
                        "[CV 8/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 5/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.775 total time= 2.7min\n",
                        "[CV 9/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500.\n",
                        "[CV 6/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.739 total time= 2.6min\n",
                        "[CV 10/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 7/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.719 total time= 2.7min\n",
                        "[CV 11/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 8/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.760 total time= 2.6min\n",
                        "[CV 12/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 9/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.772 total time= 2.7min\n",
                        "[CV 13/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 10/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.732 total time= 2.6min\n",
                        "[CV 14/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 11/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.760 total time= 2.7min\n",
                        "[CV 15/15; 16/40] START learning_rate=0.002, loss=exponential, n_estimators=1500\n",
                        "[CV 12/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.788 total time= 2.7min\n",
                        "[CV 1/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 13/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.741 total time= 2.6min\n",
                        "[CV 2/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 14/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.701 total time= 2.7min\n",
                        "[CV 3/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 15/15; 16/40] END learning_rate=0.002, loss=exponential, n_estimators=1500;, score=0.728 total time= 2.7min\n",
                        "[CV 4/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 1/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.771 total time= 3.5min\n",
                        "[CV 5/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 2/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.762 total time= 3.5min\n",
                        "[CV 6/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 3/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.731 total time= 3.5min\n",
                        "[CV 7/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 4/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.693 total time= 3.5min\n",
                        "[CV 8/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 5/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.774 total time= 3.5min\n",
                        "[CV 9/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000.\n",
                        "[CV 6/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.739 total time= 3.5min\n",
                        "[CV 10/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 7/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.714 total time= 3.5min\n",
                        "[CV 11/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 8/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.759 total time= 3.5min\n",
                        "[CV 12/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 9/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.771 total time= 3.5min\n",
                        "[CV 13/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 10/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.730 total time= 3.6min\n",
                        "[CV 14/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 11/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.758 total time= 3.5min\n",
                        "[CV 15/15; 17/40] START learning_rate=0.002, loss=exponential, n_estimators=2000\n",
                        "[CV 12/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.784 total time= 3.6min\n",
                        "[CV 1/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 13/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.742 total time= 3.5min\n",
                        "[CV 2/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 14/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.699 total time= 3.5min\n",
                        "[CV 3/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 15/15; 17/40] END learning_rate=0.002, loss=exponential, n_estimators=2000;, score=0.728 total time= 3.6min\n",
                        "[CV 4/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 1/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.767 total time= 5.4min\n",
                        "[CV 5/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 2/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.753 total time= 5.5min\n",
                        "[CV 6/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 3/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.728 total time= 5.4min\n",
                        "[CV 7/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 4/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.692 total time= 5.3min\n",
                        "[CV 8/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 5/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.767 total time= 5.3min\n",
                        "[CV 9/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000.\n",
                        "[CV 6/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.732 total time= 5.1min\n",
                        "[CV 10/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 7/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.708 total time= 5.2min\n",
                        "[CV 11/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 8/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.757 total time= 5.2min\n",
                        "[CV 12/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 9/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.765 total time= 5.2min\n",
                        "[CV 13/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 10/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.726 total time= 5.1min\n",
                        "[CV 14/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 11/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.753 total time= 5.2min\n",
                        "[CV 15/15; 18/40] START learning_rate=0.002, loss=exponential, n_estimators=3000\n",
                        "[CV 12/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.773 total time= 5.2min\n",
                        "[CV 1/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 13/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.738 total time= 5.2min\n",
                        "[CV 2/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 14/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.697 total time= 5.1min\n",
                        "[CV 3/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 15/15; 18/40] END learning_rate=0.002, loss=exponential, n_estimators=3000;, score=0.726 total time= 5.2min\n",
                        "[CV 4/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 1/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.760 total time= 6.7min\n",
                        "[CV 5/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 2/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.740 total time= 6.8min\n",
                        "[CV 6/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 3/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.724 total time= 6.7min\n",
                        "[CV 7/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 4/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.687 total time= 6.7min\n",
                        "[CV 8/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 5/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.758 total time= 6.7min\n",
                        "[CV 9/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000.\n",
                        "[CV 6/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.720 total time= 6.8min\n",
                        "[CV 10/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 7/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.700 total time= 6.7min\n",
                        "[CV 11/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 8/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.752 total time= 6.8min\n",
                        "[CV 12/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 9/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.756 total time= 6.7min\n",
                        "[CV 13/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 10/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.721 total time= 6.8min\n",
                        "[CV 14/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 11/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.748 total time= 6.7min\n",
                        "[CV 15/15; 19/40] START learning_rate=0.002, loss=exponential, n_estimators=4000\n",
                        "[CV 12/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.759 total time= 6.9min\n",
                        "[CV 1/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 13/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.729 total time= 6.8min\n",
                        "[CV 2/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 14/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.695 total time= 6.8min\n",
                        "[CV 3/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 15/15; 19/40] END learning_rate=0.002, loss=exponential, n_estimators=4000;, score=0.720 total time= 6.7min\n",
                        "[CV 4/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 1/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.749 total time= 8.2min\n",
                        "[CV 5/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 2/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.726 total time= 8.3min\n",
                        "[CV 6/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 3/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.717 total time= 8.3min\n",
                        "[CV 7/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 4/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.679 total time= 8.2min\n",
                        "[CV 8/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 5/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.748 total time= 8.3min\n",
                        "[CV 9/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000.\n",
                        "[CV 6/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.709 total time= 8.3min\n",
                        "[CV 10/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 7/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.694 total time= 8.3min\n",
                        "[CV 11/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 8/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.743 total time= 8.4min\n",
                        "[CV 12/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 9/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.744 total time= 8.3min\n",
                        "[CV 13/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 10/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.716 total time= 8.3min\n",
                        "[CV 14/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 11/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.741 total time= 9.0min\n",
                        "[CV 15/15; 20/40] START learning_rate=0.002, loss=exponential, n_estimators=5000\n",
                        "[CV 12/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.743 total time= 9.2min\n",
                        "[CV 1/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 1/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.771 total time=  12.3s\n",
                        "[CV 2/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 2/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.765 total time=  12.2s\n",
                        "[CV 3/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 3/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.733 total time=  12.5s\n",
                        "[CV 4/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 4/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.697 total time=  12.2s\n",
                        "[CV 5/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 5/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.782 total time=  11.3s\n",
                        "[CV 6/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 6/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.736 total time=  14.2s\n",
                        "[CV 7/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 7/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.721 total time=  13.1s\n",
                        "[CV 8/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 8/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.765 total time=  12.6s\n",
                        "[CV 9/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100..\n",
                        "[CV 9/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.777 total time=  12.3s\n",
                        "[CV 10/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 10/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.734 total time=  12.2s\n",
                        "[CV 11/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 11/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.764 total time=  13.9s\n",
                        "[CV 12/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 12/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.792 total time=  13.6s\n",
                        "[CV 13/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 13/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.741 total time=  14.0s\n",
                        "[CV 14/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 14/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.704 total time=  12.8s\n",
                        "[CV 15/15; 21/40] START learning_rate=0.003, loss=exponential, n_estimators=100.\n",
                        "[CV 15/15; 21/40] END learning_rate=0.003, loss=exponential, n_estimators=100;, score=0.723 total time=  12.7s\n",
                        "[CV 1/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 13/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.714 total time= 9.6min\n",
                        "[CV 2/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 1/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.770 total time=  38.1s\n",
                        "[CV 3/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 2/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.764 total time=  36.7s\n",
                        "[CV 4/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 3/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.731 total time=  41.5s\n",
                        "[CV 5/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 4/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.700 total time=  41.6s\n",
                        "[CV 6/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 6/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.737 total time=  41.0s\n",
                        "[CV 7/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 5/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.781 total time=  42.7s\n",
                        "[CV 8/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 14/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.688 total time=10.0min\n",
                        "[CV 9/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.762 total time=  43.1s\n",
                        "[CV 10/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 7/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.726 total time=  44.0s\n",
                        "[CV 11/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 9/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.776 total time=  42.5s\n",
                        "[CV 12/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 10/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.735 total time=  40.8s\n",
                        "[CV 13/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 12/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.791 total time=  39.7s\n",
                        "[CV 14/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 11/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.763 total time=  41.2s\n",
                        "[CV 15/15; 22/40] START learning_rate=0.003, loss=exponential, n_estimators=300.\n",
                        "[CV 13/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.747 total time=  40.4s\n",
                        "[CV 1/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 14/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.705 total time=  40.4s\n",
                        "[CV 2/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 22/40] END learning_rate=0.003, loss=exponential, n_estimators=300;, score=0.722 total time=  41.6s\n",
                        "[CV 3/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 1/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.769 total time= 1.1min\n",
                        "[CV 4/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 2/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.767 total time= 1.1min\n",
                        "[CV 5/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 3/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.731 total time= 1.1min\n",
                        "[CV 6/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 20/40] END learning_rate=0.002, loss=exponential, n_estimators=5000;, score=0.712 total time=10.3min\n",
                        "[CV 7/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 4/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.699 total time= 1.2min\n",
                        "[CV 8/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 5/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.779 total time= 1.2min\n",
                        "[CV 9/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500..\n",
                        "[CV 6/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.735 total time= 1.2min\n",
                        "[CV 10/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 8/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.762 total time= 1.6min\n",
                        "[CV 11/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 9/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.774 total time= 1.5min\n",
                        "[CV 12/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 7/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.725 total time= 1.6min\n",
                        "[CV 13/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 10/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.733 total time= 1.6min\n",
                        "[CV 14/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 12/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.791 total time= 1.6min\n",
                        "[CV 15/15; 23/40] START learning_rate=0.003, loss=exponential, n_estimators=500.\n",
                        "[CV 13/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.746 total time= 1.7min\n",
                        "[CV 1/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 11/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.762 total time= 1.8min\n",
                        "[CV 2/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 14/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.705 total time= 1.7min\n",
                        "[CV 3/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 15/15; 23/40] END learning_rate=0.003, loss=exponential, n_estimators=500;, score=0.723 total time= 1.3min\n",
                        "[CV 4/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 1/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.771 total time= 1.9min\n",
                        "[CV 5/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 2/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.766 total time= 1.9min\n",
                        "[CV 6/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 3/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.731 total time= 1.9min\n",
                        "[CV 7/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 4/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.697 total time= 1.9min\n",
                        "[CV 8/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 5/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.775 total time= 1.8min\n",
                        "[CV 9/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800..\n",
                        "[CV 6/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.738 total time= 1.8min\n",
                        "[CV 10/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 7/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.724 total time= 1.8min\n",
                        "[CV 11/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 8/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.761 total time= 1.7min\n",
                        "[CV 12/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 9/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.771 total time= 1.9min\n",
                        "[CV 13/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 10/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.732 total time= 1.9min\n",
                        "[CV 14/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 11/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.761 total time= 1.9min\n",
                        "[CV 15/15; 24/40] START learning_rate=0.003, loss=exponential, n_estimators=800.\n",
                        "[CV 12/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.789 total time= 1.9min\n",
                        "[CV 1/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 13/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.740 total time= 1.9min\n",
                        "[CV 2/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 14/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.703 total time= 1.8min\n",
                        "[CV 3/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 15/15; 24/40] END learning_rate=0.003, loss=exponential, n_estimators=800;, score=0.724 total time= 1.9min\n",
                        "[CV 4/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 1/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.772 total time= 2.4min\n",
                        "[CV 5/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 2/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.765 total time= 2.5min\n",
                        "[CV 6/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 3/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.731 total time= 2.7min\n",
                        "[CV 7/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 4/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.696 total time= 2.7min\n",
                        "[CV 8/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 5/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.775 total time= 3.1min\n",
                        "[CV 9/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000.\n",
                        "[CV 6/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.739 total time= 2.9min\n",
                        "[CV 10/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 7/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.719 total time= 2.8min\n",
                        "[CV 11/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 8/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.761 total time= 2.8min\n",
                        "[CV 12/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 9/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.771 total time= 2.2min\n",
                        "[CV 13/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 11/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.759 total time= 2.2min\n",
                        "[CV 14/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 10/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.732 total time= 2.3min\n",
                        "[CV 15/15; 25/40] START learning_rate=0.003, loss=exponential, n_estimators=1000\n",
                        "[CV 12/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.788 total time= 2.3min\n",
                        "[CV 1/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 13/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.741 total time= 2.4min\n",
                        "[CV 2/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 14/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.701 total time= 2.5min\n",
                        "[CV 3/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 15/15; 25/40] END learning_rate=0.003, loss=exponential, n_estimators=1000;, score=0.727 total time= 2.5min\n",
                        "[CV 4/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 1/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.771 total time= 3.8min\n",
                        "[CV 5/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 2/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.761 total time= 4.0min\n",
                        "[CV 6/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 3/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.732 total time= 3.8min\n",
                        "[CV 7/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 4/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.693 total time= 3.8min\n",
                        "[CV 8/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 5/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.773 total time= 3.6min\n",
                        "[CV 9/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500.\n",
                        "[CV 6/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.737 total time= 3.4min\n",
                        "[CV 10/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 7/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.712 total time= 3.4min\n",
                        "[CV 11/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 8/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.759 total time= 3.4min\n",
                        "[CV 12/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 9/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.770 total time= 3.6min\n",
                        "[CV 13/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 10/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.729 total time= 3.9min\n",
                        "[CV 14/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 11/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.756 total time= 3.8min\n",
                        "[CV 15/15; 26/40] START learning_rate=0.003, loss=exponential, n_estimators=1500\n",
                        "[CV 12/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.781 total time= 3.8min\n",
                        "[CV 1/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 13/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.742 total time= 3.5min\n",
                        "[CV 2/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 14/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.698 total time= 3.4min\n",
                        "[CV 3/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 15/15; 26/40] END learning_rate=0.003, loss=exponential, n_estimators=1500;, score=0.728 total time= 3.6min\n",
                        "[CV 4/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 1/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.766 total time= 5.2min\n",
                        "[CV 5/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 2/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.753 total time= 5.4min\n",
                        "[CV 6/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 3/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.730 total time= 5.4min\n",
                        "[CV 7/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 4/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.691 total time= 5.4min\n",
                        "[CV 8/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 5/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.768 total time= 5.1min\n",
                        "[CV 9/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000.\n",
                        "[CV 6/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.732 total time= 5.0min\n",
                        "[CV 10/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 7/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.707 total time= 5.2min\n",
                        "[CV 11/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 8/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.758 total time= 5.1min\n",
                        "[CV 12/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 9/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.765 total time= 5.5min\n",
                        "[CV 13/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 10/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.727 total time= 5.4min\n",
                        "[CV 14/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 11/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.754 total time= 4.9min\n",
                        "[CV 15/15; 27/40] START learning_rate=0.003, loss=exponential, n_estimators=2000\n",
                        "[CV 12/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.773 total time= 4.7min\n",
                        "[CV 1/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 13/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.737 total time= 4.3min\n",
                        "[CV 2/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 14/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.698 total time= 4.6min\n",
                        "[CV 3/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 15/15; 27/40] END learning_rate=0.003, loss=exponential, n_estimators=2000;, score=0.726 total time= 5.2min\n",
                        "[CV 4/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 1/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.755 total time= 8.3min\n",
                        "[CV 5/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 2/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.733 total time= 8.6min\n",
                        "[CV 6/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 3/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.721 total time= 8.3min\n",
                        "[CV 7/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 4/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.683 total time= 7.9min\n",
                        "[CV 8/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 5/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.753 total time= 6.8min\n",
                        "[CV 9/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000.\n",
                        "[CV 6/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.715 total time= 6.4min\n",
                        "[CV 10/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 7/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.698 total time= 6.5min\n",
                        "[CV 11/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 8/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.748 total time= 6.7min\n",
                        "[CV 12/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 9/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.749 total time= 6.8min\n",
                        "[CV 13/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 10/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.718 total time= 6.8min\n",
                        "[CV 14/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 11/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.744 total time= 6.8min\n",
                        "[CV 15/15; 28/40] START learning_rate=0.003, loss=exponential, n_estimators=3000\n",
                        "[CV 12/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.752 total time= 6.8min\n",
                        "[CV 1/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 13/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.721 total time= 6.6min\n",
                        "[CV 2/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 14/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.691 total time= 6.5min\n",
                        "[CV 3/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 15/15; 28/40] END learning_rate=0.003, loss=exponential, n_estimators=3000;, score=0.716 total time= 6.3min\n",
                        "[CV 4/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 1/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.736 total time= 8.5min\n",
                        "[CV 5/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 2/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.710 total time= 8.4min\n",
                        "[CV 6/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 3/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.708 total time= 8.4min\n",
                        "[CV 7/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 4/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.669 total time= 8.3min\n",
                        "[CV 8/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 5/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.739 total time= 7.3min\n",
                        "[CV 9/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000.\n",
                        "[CV 6/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.698 total time= 7.1min\n",
                        "[CV 10/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 7/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.685 total time= 6.9min\n",
                        "[CV 11/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 8/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.731 total time= 7.0min\n",
                        "[CV 12/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 9/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.730 total time= 6.9min\n",
                        "[CV 13/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 10/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.710 total time= 6.8min\n",
                        "[CV 14/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 11/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.733 total time= 6.9min\n",
                        "[CV 15/15; 29/40] START learning_rate=0.003, loss=exponential, n_estimators=4000\n",
                        "[CV 12/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.725 total time= 7.0min\n",
                        "[CV 1/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 13/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.699 total time= 6.9min\n",
                        "[CV 2/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 14/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.681 total time= 6.8min\n",
                        "[CV 3/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 15/15; 29/40] END learning_rate=0.003, loss=exponential, n_estimators=4000;, score=0.705 total time= 6.8min\n",
                        "[CV 4/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 1/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.719 total time= 8.5min\n",
                        "[CV 5/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 2/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.686 total time= 8.5min\n",
                        "[CV 6/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 3/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.694 total time= 8.2min\n",
                        "[CV 7/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 4/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.656 total time= 8.3min\n",
                        "[CV 8/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 5/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.724 total time= 8.5min\n",
                        "[CV 9/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000.\n",
                        "[CV 6/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.678 total time= 8.6min\n",
                        "[CV 10/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 7/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.676 total time= 8.5min\n",
                        "[CV 11/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 8/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.715 total time= 8.3min\n",
                        "[CV 12/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 9/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.708 total time= 8.5min\n",
                        "[CV 13/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 10/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.699 total time= 8.4min\n",
                        "[CV 14/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 11/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.719 total time= 8.3min\n",
                        "[CV 15/15; 30/40] START learning_rate=0.003, loss=exponential, n_estimators=5000\n",
                        "[CV 12/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.704 total time= 8.5min\n",
                        "[CV 1/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 1/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.771 total time=  10.8s\n",
                        "[CV 2/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 2/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.765 total time=  12.7s\n",
                        "[CV 3/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 3/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.730 total time=  11.7s\n",
                        "[CV 4/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 4/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.700 total time=  11.9s\n",
                        "[CV 5/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 5/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.779 total time=  11.5s\n",
                        "[CV 6/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 6/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.739 total time=  11.9s\n",
                        "[CV 7/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 7/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.723 total time=  11.0s\n",
                        "[CV 8/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 8/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.763 total time=  11.0s\n",
                        "[CV 9/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100..\n",
                        "[CV 9/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.779 total time=  11.2s\n",
                        "[CV 10/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 10/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.735 total time=  11.6s\n",
                        "[CV 11/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 11/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.762 total time=  11.6s\n",
                        "[CV 12/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 12/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.789 total time=  11.3s\n",
                        "[CV 13/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 13/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.745 total time=  11.5s\n",
                        "[CV 14/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 14/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.705 total time=  11.6s\n",
                        "[CV 15/15; 31/40] START learning_rate=0.005, loss=exponential, n_estimators=100.\n",
                        "[CV 15/15; 31/40] END learning_rate=0.005, loss=exponential, n_estimators=100;, score=0.722 total time=  11.8s\n",
                        "[CV 1/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 13/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.675 total time= 8.5min\n",
                        "[CV 2/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 1/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.769 total time=  36.1s\n",
                        "[CV 3/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 2/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.766 total time=  33.9s\n",
                        "[CV 4/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 3/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.731 total time=  35.5s\n",
                        "[CV 5/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 4/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.698 total time=  34.5s\n",
                        "[CV 6/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 5/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.778 total time=  34.0s\n",
                        "[CV 7/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 6/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.736 total time=  34.8s\n",
                        "[CV 8/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 7/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.725 total time=  36.3s\n",
                        "[CV 9/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300..\n",
                        "[CV 8/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.761 total time=  33.9s\n",
                        "[CV 10/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 14/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.670 total time= 8.4min\n",
                        "[CV 11/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 9/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.772 total time=  36.4s\n",
                        "[CV 12/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 10/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.734 total time=  34.5s\n",
                        "[CV 13/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 11/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.762 total time=  34.1s\n",
                        "[CV 14/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 12/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.789 total time=  35.3s\n",
                        "[CV 15/15; 32/40] START learning_rate=0.005, loss=exponential, n_estimators=300.\n",
                        "[CV 13/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.746 total time=  34.5s\n",
                        "[CV 1/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 14/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.705 total time=  34.3s\n",
                        "[CV 2/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 32/40] END learning_rate=0.005, loss=exponential, n_estimators=300;, score=0.721 total time=  35.0s\n",
                        "[CV 3/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 15/15; 30/40] END learning_rate=0.003, loss=exponential, n_estimators=5000;, score=0.696 total time= 8.3min\n",
                        "[CV 4/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 1/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.771 total time=  57.3s\n",
                        "[CV 5/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 2/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.766 total time=  59.3s\n",
                        "[CV 6/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 3/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.731 total time=  56.4s\n",
                        "[CV 7/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 4/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.697 total time=  56.2s\n",
                        "[CV 8/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 5/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.776 total time=  57.3s\n",
                        "[CV 9/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500..\n",
                        "[CV 6/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.738 total time=  58.0s\n",
                        "[CV 10/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 7/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.721 total time=  59.2s\n",
                        "[CV 11/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 8/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.761 total time=  56.4s\n",
                        "[CV 12/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 9/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.770 total time=  57.5s\n",
                        "[CV 13/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 10/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.732 total time=  58.0s\n",
                        "[CV 14/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 11/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.761 total time=  58.3s\n",
                        "[CV 15/15; 33/40] START learning_rate=0.005, loss=exponential, n_estimators=500.\n",
                        "[CV 12/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.788 total time=  56.8s\n",
                        "[CV 1/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 13/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.740 total time=  57.0s\n",
                        "[CV 2/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 14/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.703 total time=  57.6s\n",
                        "[CV 3/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 15/15; 33/40] END learning_rate=0.005, loss=exponential, n_estimators=500;, score=0.726 total time=  56.1s\n",
                        "[CV 4/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 1/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.771 total time= 1.5min\n",
                        "[CV 5/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 2/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.761 total time= 1.5min\n",
                        "[CV 6/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 3/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.730 total time= 1.5min\n",
                        "[CV 7/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 4/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.693 total time= 1.5min\n",
                        "[CV 8/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 5/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.773 total time= 1.5min\n",
                        "[CV 9/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800..\n",
                        "[CV 6/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.739 total time= 1.5min\n",
                        "[CV 10/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 7/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.715 total time= 1.5min\n",
                        "[CV 11/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 8/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.759 total time= 1.5min\n",
                        "[CV 12/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 9/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.772 total time= 1.5min\n",
                        "[CV 13/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 10/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.730 total time= 1.5min\n",
                        "[CV 14/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 11/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.758 total time= 1.5min\n",
                        "[CV 15/15; 34/40] START learning_rate=0.005, loss=exponential, n_estimators=800.\n",
                        "[CV 12/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.784 total time= 1.5min\n",
                        "[CV 1/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 13/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.742 total time= 1.5min\n",
                        "[CV 2/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 14/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.698 total time= 1.5min\n",
                        "[CV 3/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 15/15; 34/40] END learning_rate=0.005, loss=exponential, n_estimators=800;, score=0.729 total time= 1.5min\n",
                        "[CV 4/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 1/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.769 total time= 1.9min\n",
                        "[CV 5/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 2/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.759 total time= 1.8min\n",
                        "[CV 6/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 3/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.730 total time= 1.9min\n",
                        "[CV 7/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 4/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.692 total time= 1.8min\n",
                        "[CV 8/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 5/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.771 total time= 1.8min\n",
                        "[CV 9/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000.\n",
                        "[CV 6/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.736 total time= 1.8min\n",
                        "[CV 10/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 7/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.712 total time= 1.9min\n",
                        "[CV 11/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 8/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.758 total time= 1.8min\n",
                        "[CV 12/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 9/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.769 total time= 1.8min\n",
                        "[CV 13/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 10/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.728 total time= 1.9min\n",
                        "[CV 14/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 11/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.755 total time= 1.9min\n",
                        "[CV 15/15; 35/40] START learning_rate=0.005, loss=exponential, n_estimators=1000\n",
                        "[CV 12/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.778 total time= 1.9min\n",
                        "[CV 1/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 13/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.740 total time= 1.8min\n",
                        "[CV 2/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 14/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.697 total time= 1.8min\n",
                        "[CV 3/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 15/15; 35/40] END learning_rate=0.005, loss=exponential, n_estimators=1000;, score=0.727 total time= 1.9min\n",
                        "[CV 4/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 1/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.761 total time= 2.7min\n",
                        "[CV 5/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 2/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.744 total time= 2.7min\n",
                        "[CV 6/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 3/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.726 total time= 2.7min\n",
                        "[CV 7/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 4/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.688 total time= 2.7min\n",
                        "[CV 8/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 5/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.761 total time= 2.7min\n",
                        "[CV 9/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500.\n",
                        "[CV 6/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.724 total time= 2.7min\n",
                        "[CV 10/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 7/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.703 total time= 2.7min\n",
                        "[CV 11/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 8/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.754 total time= 2.7min\n",
                        "[CV 12/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 9/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.759 total time= 2.8min\n",
                        "[CV 13/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 10/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.723 total time= 2.7min\n",
                        "[CV 14/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 11/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.750 total time= 2.7min\n",
                        "[CV 15/15; 36/40] START learning_rate=0.005, loss=exponential, n_estimators=1500\n",
                        "[CV 12/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.764 total time= 2.8min\n",
                        "[CV 1/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 13/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.731 total time= 2.7min\n",
                        "[CV 2/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 14/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.696 total time= 2.7min\n",
                        "[CV 3/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 15/15; 36/40] END learning_rate=0.005, loss=exponential, n_estimators=1500;, score=0.722 total time= 2.7min\n",
                        "[CV 4/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 1/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.749 total time= 3.5min\n",
                        "[CV 5/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 2/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.726 total time= 3.6min\n",
                        "[CV 6/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 3/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.717 total time= 3.5min\n",
                        "[CV 7/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 4/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.679 total time= 3.5min\n",
                        "[CV 8/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 5/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.748 total time= 3.5min\n",
                        "[CV 9/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000.\n",
                        "[CV 6/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.710 total time= 3.5min\n",
                        "[CV 10/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 7/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.694 total time= 3.5min\n",
                        "[CV 11/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 8/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.743 total time= 3.4min\n",
                        "[CV 12/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 9/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.744 total time= 3.6min\n",
                        "[CV 13/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 10/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.715 total time= 3.5min\n",
                        "[CV 14/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 11/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.740 total time= 3.6min\n",
                        "[CV 15/15; 37/40] START learning_rate=0.005, loss=exponential, n_estimators=2000\n",
                        "[CV 12/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.744 total time= 3.5min\n",
                        "[CV 1/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 13/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.715 total time= 3.5min\n",
                        "[CV 2/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 14/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.689 total time= 3.5min\n",
                        "[CV 3/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 15/15; 37/40] END learning_rate=0.005, loss=exponential, n_estimators=2000;, score=0.713 total time= 3.5min\n",
                        "[CV 4/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 1/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.719 total time= 5.0min\n",
                        "[CV 5/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 2/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.684 total time= 5.0min\n",
                        "[CV 6/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 3/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.695 total time= 5.0min\n",
                        "[CV 7/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 4/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.656 total time= 5.0min\n",
                        "[CV 8/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 5/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.724 total time= 5.0min\n",
                        "[CV 9/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000.\n",
                        "[CV 6/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.678 total time= 5.2min\n",
                        "[CV 10/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 7/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.676 total time= 5.0min\n",
                        "[CV 11/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 8/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.715 total time= 5.0min\n",
                        "[CV 12/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 9/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.708 total time= 5.1min\n",
                        "[CV 13/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 10/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.698 total time= 5.1min\n",
                        "[CV 14/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 11/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.719 total time= 5.0min\n",
                        "[CV 15/15; 38/40] START learning_rate=0.005, loss=exponential, n_estimators=3000\n",
                        "[CV 12/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.703 total time= 5.1min\n",
                        "[CV 1/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 13/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.675 total time= 5.0min\n",
                        "[CV 2/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 14/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.669 total time= 5.1min\n",
                        "[CV 3/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 15/15; 38/40] END learning_rate=0.005, loss=exponential, n_estimators=3000;, score=0.696 total time= 5.0min\n",
                        "[CV 4/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 1/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.695 total time= 6.4min\n",
                        "[CV 5/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 2/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.651 total time= 6.5min\n",
                        "[CV 6/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 3/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.672 total time= 6.5min\n",
                        "[CV 7/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 4/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.640 total time= 6.3min\n",
                        "[CV 8/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 5/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.706 total time= 6.5min\n",
                        "[CV 9/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000.\n",
                        "[CV 6/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.649 total time= 6.4min\n",
                        "[CV 10/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 7/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.659 total time= 6.4min\n",
                        "[CV 11/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 8/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.691 total time= 6.4min\n",
                        "[CV 12/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 9/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.681 total time= 6.4min\n",
                        "[CV 13/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 10/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.680 total time= 6.4min\n",
                        "[CV 14/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 11/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.695 total time= 6.3min\n",
                        "[CV 15/15; 39/40] START learning_rate=0.005, loss=exponential, n_estimators=4000\n",
                        "[CV 12/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.674 total time= 6.5min\n",
                        "[CV 1/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 13/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.646 total time= 6.3min\n",
                        "[CV 2/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 14/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.649 total time= 6.4min\n",
                        "[CV 3/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 15/15; 39/40] END learning_rate=0.005, loss=exponential, n_estimators=4000;, score=0.681 total time= 6.5min\n",
                        "[CV 4/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 1/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.672 total time= 7.8min\n",
                        "[CV 5/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 2/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.626 total time= 7.7min\n",
                        "[CV 6/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 3/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.653 total time= 7.6min\n",
                        "[CV 7/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 4/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.627 total time= 7.7min\n",
                        "[CV 8/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 5/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.695 total time= 7.6min\n",
                        "[CV 9/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000.\n",
                        "[CV 6/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.629 total time= 7.7min\n",
                        "[CV 10/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 7/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.645 total time= 7.6min\n",
                        "[CV 11/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 8/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.669 total time= 7.7min\n",
                        "[CV 12/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 9/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.664 total time= 7.7min\n",
                        "[CV 13/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 10/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.660 total time= 7.6min\n",
                        "[CV 14/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 11/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.675 total time= 7.7min\n",
                        "[CV 15/15; 40/40] START learning_rate=0.005, loss=exponential, n_estimators=5000\n",
                        "[CV 12/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.648 total time= 7.8min\n",
                        "[CV 13/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.619 total time= 7.1min\n",
                        "[CV 14/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.635 total time= 6.7min\n",
                        "[CV 15/15; 40/40] END learning_rate=0.005, loss=exponential, n_estimators=5000;, score=0.667 total time= 5.9min\n",
                        "Best: 0.7475308262718612 using {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 300, 'scoring': 'r2', 'best_score': 0.7475308262718612, 'n_splits': 5, 'n_repeats': 3} \n",
                        "\n",
                        "0.7469840633650208 (0.0277642639228335) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.7475308262718612 (0.027648456138034346) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 300, 'scoring': 'r2', 'best_score': 0.7475308262718612, 'n_splits': 5, 'n_repeats': 3} \n",
                        "\n",
                        "0.7472121074654211 (0.02712397836593884) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.7473064771221808 (0.027141604575774206) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.7469550979217416 (0.026763217908191556) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.7465374984709189 (0.02654956219809589) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.7459992280991604 (0.026544912926983105) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.7449983169884611 (0.026712232865649426) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.743610873337004 (0.02708308034462806) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.7416548834614711 (0.026100638050546004) with: {'learning_rate': 0.001, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n",
                        "0.7468574748226863 (0.02809948994261432) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.7475220506785809 (0.026852378440772137) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.7471332666860201 (0.02690591015256807) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.7463885292736049 (0.026427558696443736) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.7458235984170485 (0.026388893742337615) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.7450934458095421 (0.026762301301164398) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.7435245637330469 (0.02701132320044) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.7388728189024505 (0.02519922043113198) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.7312171467918203 (0.023686952639740785) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.7215226148109085 (0.02206197779677646) with: {'learning_rate': 0.002, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n",
                        "0.7470110270641448 (0.028008979623934498) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.7473479571290176 (0.02691475155594805) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.7467712790394044 (0.026762088296343904) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.7456095567759022 (0.026565886301292554) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.7449861846586664 (0.026701429168264998) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.7426991238237771 (0.026653328981221032) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.7390495376840847 (0.02530070578202874) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.7265853733962501 (0.022870181602174272) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.7107072783840115 (0.020919517438126263) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.694634457519932 (0.019953596391344846) with: {'learning_rate': 0.003, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n",
                        "0.7472935862312092 (0.026966358186899023) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 100} \n",
                        "\n",
                        "0.7461715865844835 (0.026567321957504247) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 300} \n",
                        "\n",
                        "0.745384413063967 (0.026360533245217647) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 500} \n",
                        "\n",
                        "0.7436011312468143 (0.026930755298845605) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 800} \n",
                        "\n",
                        "0.7415368120052579 (0.026137609283167114) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 1000} \n",
                        "\n",
                        "0.7337408476855761 (0.023991650298278294) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 1500} \n",
                        "\n",
                        "0.7215150825773057 (0.02189851608591681) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 2000} \n",
                        "\n",
                        "0.6943757179585984 (0.02000076592323366) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 3000} \n",
                        "\n",
                        "0.6711591827905566 (0.02029446153687833) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 4000} \n",
                        "\n",
                        "0.6521808449203836 (0.021221509823996138) with: {'learning_rate': 0.005, 'loss': 'exponential', 'n_estimators': 5000} \n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'learning_rate': 0.001,\n",
                            " 'loss': 'exponential',\n",
                            " 'n_estimators': 300,\n",
                            " 'scoring': 'r2',\n",
                            " 'best_score': 0.7475308262718612,\n",
                            " 'n_splits': 5,\n",
                            " 'n_repeats': 3}"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "grid_search_optimization(X,y,\n",
                "                            n_estimators_v,\n",
                "                            learning_rate_v,\n",
                "                            scoring_metric=\"r2\",\n",
                "                            loss_functions_list=loss_function_v,\n",
                "                            n_cores = -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_estimator_opt=100\n",
                "learning_rate_opt=0.005"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The r2 of prediction is: 0.7695954712551589\n",
                        "The MSE of prediction is: 0.10748013499204866\n",
                        "The RMSE of prediction is: 0.3278416309623423\n",
                        "The MAE of prediction is: 0.20688348046896105\n"
                    ]
                }
            ],
            "source": [
                "model = AdaBoostRegressor(n_estimators=n_estimator_opt,learning_rate=learning_rate_opt,loss=\"exponential\")\n",
                "model.fit(X_train,Y_train)\n",
                "pred=model.predict(X_test)\n",
                "# REGRESION MODEL METRICS\n",
                "print(\"The r2 of prediction is:\", r2_score(Y_test, pred))\n",
                "print(\"The MSE of prediction is:\", mean_squared_error(Y_test, pred, squared=True))\n",
                "print(\"The RMSE of prediction is:\", mean_squared_error(Y_test, pred, squared=False))\n",
                "print(\"The MAE of prediction is:\", mean_absolute_error(Y_test, pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "filename = \"adaboost_filtered_trees_{}_learning_rate_{}.sav\".format(n_estimator_opt, learning_rate_opt)\n",
                "pickle.dump(model, open(filename, 'wb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load the model from disk\n",
                "filename = \"adaboost_filtered_trees_{}_learning_rate_{}.sav\".format(n_estimator_opt, learning_rate_opt)\n",
                "\n",
                "loaded_model = pickle.load(open(filename, 'rb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bla=loaded_model.predict(X_test)\n",
                "# REGRESION MODEL METRICS\n",
                "print(\"The r2 of prediction is:\", r2_score(Y_test, bla))\n",
                "print(\"The MSE of prediction is:\", mean_squared_error(Y_test, bla, squared=True))\n",
                "print(\"The RMSE of prediction is:\", mean_squared_error(Y_test, bla, squared=False))\n",
                "print(\"The MAE of prediction is:\", mean_absolute_error(Y_test, bla))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "# list_of_filenames=[\n",
                "#                     \"adaboost_unfiltered_trees_100_learning_rate_0.001.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_300_learning_rate_0.001.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_500_learning_rate_0.001.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_800_learning_rate_0.001.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_100_learning_rate_0.002.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_300_learning_rate_0.002.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_100_learning_rate_0.003.sav\",\n",
                "#                     \"adaboost_unfiltered_trees_300_learning_rate_0.003.sav\",\n",
                "#                     ]\n",
                "\n",
                "list_of_filenames=[\n",
                "                    \"adaboost_filtered_trees_300_learning_rate_0.001.sav\",\n",
                "                    \"adaboost_filtered_trees_500_learning_rate_0.001.sav\",\n",
                "                    \"adaboost_filtered_trees_800_learning_rate_0.001.sav\",\n",
                "                    \"adaboost_filtered_trees_300_learning_rate_0.002.sav\",\n",
                "                    \"adaboost_filtered_trees_500_learning_rate_0.002.sav\",\n",
                "                    \"adaboost_filtered_trees_100_learning_rate_0.003.sav\",\n",
                "                    \"adaboost_filtered_trees_300_learning_rate_0.003.sav\",\n",
                "                    \"adaboost_filtered_trees_100_learning_rate_0.005.sav\",  \n",
                "                ]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'0.001'"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#list_of_filenames[0][44:49]\n",
                "list_of_filenames[0][42:47]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'300'"
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "list_of_filenames[0][24:27]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(columns=['trees','learning_rate','r2','MSE','RMSE','MAE'])\n",
                "for i in list_of_filenames:\n",
                "    loaded_model = pickle.load(open(i, 'rb'))\n",
                "    prediction_over_x_test=loaded_model.predict(X_test)\n",
                "    # print(i)\n",
                "    # print(\"\\n\")\n",
                "    # REGRESION MODEL METRICS\n",
                "    trees = i[24:27]\n",
                "    lr = i[42:47]\n",
                "    r2=r2_score(Y_test, prediction_over_x_test)\n",
                "    MSE=mean_squared_error(Y_test, prediction_over_x_test, squared=True)\n",
                "    RMSE = mean_squared_error(Y_test, prediction_over_x_test, squared=False)\n",
                "    MAE = mean_absolute_error(Y_test, prediction_over_x_test)\n",
                "    # print(\"The r2 of prediction is:\", r2)\n",
                "    # print(\"The MSE of prediction is:\", MSE)\n",
                "    # print(\"The RMSE of prediction is:\", RMSE)\n",
                "    # print(\"The MAE of prediction is:\", MAE)\n",
                "    to_append = [trees,lr,r2,MSE,RMSE,MAE]\n",
                "    a_series = pd.Series(to_append, index = results_df.columns)\n",
                "    results_df = results_df.append(a_series, ignore_index=True)\n",
                "    loaded_model = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>trees</th>\n",
                            "      <th>learning_rate</th>\n",
                            "      <th>r2</th>\n",
                            "      <th>MSE</th>\n",
                            "      <th>RMSE</th>\n",
                            "      <th>MAE</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>300</td>\n",
                            "      <td>0.001</td>\n",
                            "      <td>0.767512</td>\n",
                            "      <td>0.108452</td>\n",
                            "      <td>0.329320</td>\n",
                            "      <td>0.208473</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>500</td>\n",
                            "      <td>0.001</td>\n",
                            "      <td>0.768204</td>\n",
                            "      <td>0.108129</td>\n",
                            "      <td>0.328830</td>\n",
                            "      <td>0.207558</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>800</td>\n",
                            "      <td>0.001</td>\n",
                            "      <td>0.768127</td>\n",
                            "      <td>0.108165</td>\n",
                            "      <td>0.328885</td>\n",
                            "      <td>0.208145</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>300</td>\n",
                            "      <td>0.002</td>\n",
                            "      <td>0.768941</td>\n",
                            "      <td>0.107785</td>\n",
                            "      <td>0.328307</td>\n",
                            "      <td>0.207833</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>500</td>\n",
                            "      <td>0.002</td>\n",
                            "      <td>0.767990</td>\n",
                            "      <td>0.108229</td>\n",
                            "      <td>0.328982</td>\n",
                            "      <td>0.209472</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>100</td>\n",
                            "      <td>0.003</td>\n",
                            "      <td>0.768221</td>\n",
                            "      <td>0.108122</td>\n",
                            "      <td>0.328818</td>\n",
                            "      <td>0.207255</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>300</td>\n",
                            "      <td>0.003</td>\n",
                            "      <td>0.767585</td>\n",
                            "      <td>0.108418</td>\n",
                            "      <td>0.329269</td>\n",
                            "      <td>0.209590</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>100</td>\n",
                            "      <td>0.005</td>\n",
                            "      <td>0.769595</td>\n",
                            "      <td>0.107480</td>\n",
                            "      <td>0.327842</td>\n",
                            "      <td>0.206883</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  trees learning_rate        r2       MSE      RMSE       MAE\n",
                            "0   300         0.001  0.767512  0.108452  0.329320  0.208473\n",
                            "1   500         0.001  0.768204  0.108129  0.328830  0.207558\n",
                            "2   800         0.001  0.768127  0.108165  0.328885  0.208145\n",
                            "3   300         0.002  0.768941  0.107785  0.328307  0.207833\n",
                            "4   500         0.002  0.767990  0.108229  0.328982  0.209472\n",
                            "5   100         0.003  0.768221  0.108122  0.328818  0.207255\n",
                            "6   300         0.003  0.767585  0.108418  0.329269  0.209590\n",
                            "7   100         0.005  0.769595  0.107480  0.327842  0.206883"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.round(results_df,5).to_csv(\"adaboost_results_filtered_dataframe.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.7695954712551589"
                        ]
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results_df[\"r2\"].max()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6a229a7624aaca0bb64305d3a84f8aa11ea5a7132c8c99f127f8b64a260fdc5c"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit (conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
