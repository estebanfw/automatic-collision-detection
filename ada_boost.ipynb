{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data=pd.read_pickle(\"./dataframe/df_only_risky_events.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test = train_test_split(data, test_size=0.25, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
                "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Y_train = train[\"COLLISSION_PROBABILITY\"]\n",
                "X_train= train.drop([\"COLLISSION_PROBABILITY\"], axis=1)\n",
                "Y_test = test[\"COLLISSION_PROBABILITY\"]\n",
                "X_test= test.drop([\"COLLISSION_PROBABILITY\"], axis=1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#print(list(X.columns))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from sklearn.model_selection import RepeatedKFold\n",
                "# from sklearn.model_selection import GridSearchCV\n",
                "# from sklearn.ensemble import AdaBoostRegressor\n",
                "# import datetime as dt\n",
                "# import pickle\n",
                "\n",
                "# # define the model with default hyperparameters\n",
                "# model = AdaBoostRegressor()\n",
                "# # define the grid of values to search\n",
                "# grid = dict()\n",
                "# #grid['n_estimators'] = [10, 50, 100, 500,1000,1500,2000,3000]\n",
                "# grid['n_estimators'] = [10, 50]\n",
                "# grid['learning_rate'] = [0.0001, 0.001]\n",
                "# # define the evaluation procedure\n",
                "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
                "# # define the grid search procedure\n",
                "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='r2')\n",
                "\n",
                "# # execute the grid search\n",
                "# grid_result = grid_search.fit(X, y)\n",
                "\n",
                "# # summarize the best score and configuration\n",
                "# now=dt.datetime.now()\n",
                "# filename1=\"./opt_parameters_ada_boost/{}_gs_opt_param.pkl\".format(\n",
                "#         now.strftime(\"%Y%m%d_%H%M%S\"))\n",
                "# filename2=\"./opt_parameters_ada_boost/{}_gs_full_run.txt\".format(\n",
                "#         now.strftime(\"%Y%m%d_%H%M%S\"))\n",
                "# with open(filename1, \"wb\") as optimal_parameters_logger:\n",
                "#     output_dict = grid_result.best_params_\n",
                "#     pickle.dump(output_dict, optimal_parameters_logger)\n",
                "#     optimal_parameters_logger.close()\n",
                "# with open(filename2, \"a\") as results_logger:\n",
                "#     output_1 = \"Best: {} using {} \\n\".format(grid_result.best_score_, grid_result.best_params_)\n",
                "#     print(output_1)\n",
                "#     results_logger.write(output_1)\n",
                "#     # summarize all scores that were evaluated\n",
                "#     means = grid_result.cv_results_['mean_test_score']\n",
                "#     stds = grid_result.cv_results_['std_test_score']\n",
                "#     params = grid_result.cv_results_['params']\n",
                "#     for mean, stdev, param in zip(means, stds, params):\n",
                "#         output_2 = \"{} ({}) with: {} \\n\".format(mean, stdev, param)\n",
                "#         #print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
                "#         print(output_2)\n",
                "#         results_logger.write(output_2)\n",
                "#     results_logger.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import RepeatedKFold\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.ensemble import AdaBoostRegressor\n",
                "import datetime as dt\n",
                "import pickle\n",
                "\n",
                "\n",
                "def grid_search_optimization(\n",
                "    X,\n",
                "    y,\n",
                "    n_estimators_list=[10, 50],\n",
                "    learning_rate_list=[0.0001, 0.001],\n",
                "    loss_functions_list = [\"linear\"],\n",
                "    scoring_metric=\"r2\",\n",
                "    n_splits_for_cv = 5,\n",
                "    n_repeats_for_cv = 3\n",
                "):\n",
                "    \"\"\"Computes the optimal values for the LGBM model\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    X : dataframe\n",
                "        Train dataset\n",
                "    y : target dataframe\n",
                "        Values to be predicted\n",
                "    n_estimators_list: list\n",
                "        List of n_estimators values for grid search\n",
                "    learning_rate_list: list\n",
                "        List of learning_rate values for grid search\n",
                "    scoring_metric: \n",
                "        Scoring metrics from sci-kit learn default r2\n",
                "    n_splits_for_cv:\n",
                "        Number of splits for K Fold cross validation\n",
                "    n_repeats_for_cv:\n",
                "        Number of repetition for cross validation\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    dictionary\n",
                "        Optimized values\n",
                "    \"\"\"\n",
                "    # define the model with default hyperparameters\n",
                "    model = AdaBoostRegressor()\n",
                "    # define the grid of values to search\n",
                "    grid = dict()\n",
                "    #grid['n_estimators'] = [10, 50, 100, 500,1000,1500,2000,3000]\n",
                "    grid['n_estimators'] = n_estimators_list\n",
                "    grid['learning_rate'] = learning_rate_list\n",
                "    grid['loss'] = loss_functions_list\n",
                "    # define the evaluation procedure\n",
                "    cv = RepeatedKFold(n_splits=n_splits_for_cv, n_repeats=n_repeats_for_cv, random_state=1)\n",
                "    # define the grid search procedure\n",
                "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring=scoring_metric)\n",
                "\n",
                "    # execute the grid search\n",
                "    grid_result = grid_search.fit(X, y)\n",
                "\n",
                "    # summarize the best score and configuration\n",
                "    now=dt.datetime.now()\n",
                "    filename1=\"./opt_parameters_ada_boost/{}_{}_gs_opt_param.pkl\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    filename2=\"./opt_parameters_ada_boost/{}_gs_full_run.txt\".format(\n",
                "            now.strftime(\"%Y%m%d_%H%M%S\"),scoring_metric)\n",
                "    with open(filename1, \"wb\") as optimal_parameters_logger:\n",
                "        output_dict = grid_result.best_params_\n",
                "        output_dict[\"scoring\"] = scoring_metric\n",
                "        output_dict[\"best_score\"] = grid_result.best_score_\n",
                "        output_dict[\"n_splits\"] = n_splits_for_cv\n",
                "        output_dict[\"n_repeats\"] = n_repeats_for_cv\n",
                "        pickle.dump(output_dict, optimal_parameters_logger)\n",
                "        optimal_parameters_logger.close()\n",
                "    with open(filename2, \"a\") as results_logger:\n",
                "        output_1 = \"Best: {} using {} \\n\".format(grid_result.best_score_, grid_result.best_params_)\n",
                "        print(output_1)\n",
                "        results_logger.write(output_1)\n",
                "        # summarize all scores that were evaluated\n",
                "        means = grid_result.cv_results_['mean_test_score']\n",
                "        stds = grid_result.cv_results_['std_test_score']\n",
                "        params = grid_result.cv_results_['params']\n",
                "        for mean, stdev, param in zip(means, stds, params):\n",
                "            output_2 = \"{} ({}) with: {} \\n\".format(mean, stdev, param)\n",
                "            print(output_2)\n",
                "            results_logger.write(output_2)\n",
                "        results_logger.close()\n",
                "    return output_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_estimators_v=list(range(50,4025,25))\n",
                "learning_rate_v=[0.001,0.002,0.0025,0.005,0.0075,0.01,0.0125,0.015,0.0175,0.02,0.025,0.03,0.04,0.05]\n",
                "loss_function_v = [\"linear\",\"exponential\"]\n",
                "regression_metrics=[\"r2\",\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"neg_root_mean_squared_error\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in regression_metrics:\n",
                "    grid_search_optimization(X,y,n_estimators_v,learning_rate_v,scoring_metric=i,loss_functions_list=loss_function_v)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "6a229a7624aaca0bb64305d3a84f8aa11ea5a7132c8c99f127f8b64a260fdc5c"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit (conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
