{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "\"param_20211225_221002_lgb_r2\",\n",
    "\"param_20211226_020611_lgb_r2\",\n",
    "\"param_20211226_063335_lgb_r2\",\n",
    "\"param_20211226_124634_lgb_r2\",\n",
    "\"param_20211226_200801_lgb_r2\",\n",
    "\"param_20211227_044955_lgb_r2\",\n",
    "\"param_20211227_150531_lgb_r2\",\n",
    "\"param_20211228_024736_lgb_r2\",\n",
    "\"param_20211228_150337_lgb_r2\",\n",
    "\"param_20211229_052509_lgb_r2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>min_split_gain</th>\n",
       "      <th>num_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.773690</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>10.785873</td>\n",
       "      <td>31.929489</td>\n",
       "      <td>0.052102</td>\n",
       "      <td>76.509752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.873829</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>13.163268</td>\n",
       "      <td>22.375637</td>\n",
       "      <td>0.079443</td>\n",
       "      <td>112.488813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.550458</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>11.156657</td>\n",
       "      <td>23.601607</td>\n",
       "      <td>0.044143</td>\n",
       "      <td>117.028324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800.0</td>\n",
       "      <td>0.512259</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>14.292298</td>\n",
       "      <td>22.587077</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>89.224429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.596051</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>11.066419</td>\n",
       "      <td>18.884203</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>77.673244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.635012</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>14.911514</td>\n",
       "      <td>15.489362</td>\n",
       "      <td>0.072152</td>\n",
       "      <td>66.441209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.595875</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>14.968178</td>\n",
       "      <td>26.698639</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>45.232441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.574175</td>\n",
       "      <td>0.015431</td>\n",
       "      <td>14.918495</td>\n",
       "      <td>14.771595</td>\n",
       "      <td>0.039918</td>\n",
       "      <td>51.171294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>11.511435</td>\n",
       "      <td>15.246240</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>51.122274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.615453</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>14.607361</td>\n",
       "      <td>18.532297</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>62.416575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_iterations  feature_fraction  learning_rate  max_depth  \\\n",
       "0           100.0          0.773690       0.044289  10.785873   \n",
       "1           300.0          0.873829       0.042837  13.163268   \n",
       "2           500.0          0.550458       0.033637  11.156657   \n",
       "3           800.0          0.512259       0.027469  14.292298   \n",
       "4          1000.0          0.596051       0.023397  11.066419   \n",
       "5          1500.0          0.635012       0.016797  14.911514   \n",
       "6          2000.0          0.595875       0.021943  14.968178   \n",
       "7          3000.0          0.574175       0.015431  14.918495   \n",
       "8          4000.0          0.574572       0.007813  11.511435   \n",
       "9          5000.0          0.615453       0.006055  14.607361   \n",
       "\n",
       "   min_child_weight  min_split_gain  num_leaves  \n",
       "0         31.929489        0.052102   76.509752  \n",
       "1         22.375637        0.079443  112.488813  \n",
       "2         23.601607        0.044143  117.028324  \n",
       "3         22.587077        0.008829   89.224429  \n",
       "4         18.884203        0.022244   77.673244  \n",
       "5         15.489362        0.072152   66.441209  \n",
       "6         26.698639        0.015569   45.232441  \n",
       "7         14.771595        0.039918   51.171294  \n",
       "8         15.246240        0.032439   51.122274  \n",
       "9         18.532297        0.008600   62.416575  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 0\n",
    "df = pd.DataFrame()\n",
    "for i in filenames:\n",
    "    filename = str(\"./opt_parameters_bo/{}.pkl\".format(i))\n",
    "    a_file = open(filename, \"rb\")\n",
    "    opt_parameters = pickle.load(a_file)\n",
    "    #print(opt_parameters)\n",
    "    data_items = opt_parameters.items()\n",
    "    data_list = list(data_items)\n",
    "    #if j == 0:\n",
    "    #    df = pd.DataFrame(data_list)\n",
    "    #else:\n",
    "    \n",
    "    df = df.append(opt_parameters, ignore_index=True, sort=False)\n",
    "        #aux = pd.DataFrame(data_list)\n",
    "        #df[str(j)]=pd.Series(aux)\n",
    "    j = j + 1\n",
    "df.drop([\"bagging_fraction\",\"num_iterations\"],inplace=True, axis=1)\n",
    "df.rename(columns={\"n_estimators\":\"num_iterations\"},inplace=True)\n",
    "df=df[ ['num_iterations'] + [ col for col in df.columns if col != 'num_iterations' ] ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    filename = str(\"./opt_parameters_bo/{}.pkl\".format(name))\n",
    "    a_file = open(filename, \"rb\")\n",
    "    opt_parameters = pickle.load(a_file)\n",
    "    print(\"------------------------ OPTIMAL PARAMETERS ------------------------\")\n",
    "    print(opt_parameters)\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "    # LOAD OPTIMAL PARAMETERS FOR FURTHER COMPUTATION\n",
    "    hyper_params = {\n",
    "        \"task\": \"train\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": str(hp_metric),\n",
    "        \"learning_rate\": opt_parameters.get(\"learning_rate\"),\n",
    "        \"feature_fraction\": opt_parameters.get(\"feature_fraction\"),\n",
    "        \"bagging_fraction\": opt_parameters.get(\"bagging_fraction\"),\n",
    "        \"verbose\": -1,\n",
    "        \"max_depth\": int(round(opt_parameters.get(\"max_depth\"))),\n",
    "        \"num_leaves\": int(round(opt_parameters.get(\"num_leaves\"))),\n",
    "        \"min_split_gain\": opt_parameters.get(\"min_split_gain\"),\n",
    "        \"num_iterations\": opt_parameters.get(\"num_iterations\"),\n",
    "        \"n_estimators\": opt_parameters.get(\"n_estimators\"),\n",
    "        \"min_child_weight\": opt_parameters.get(\"min_child_weight\"),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3f0306f65ef94eb1724025cbafa0368c3a6fe3ff428a97c0fe1d1daabf31713"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
