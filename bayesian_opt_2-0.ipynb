{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import lightgbm as lgb\n",
                "from bayes_opt import BayesianOptimization\n",
                "from sklearn.datasets import load_boston\n",
                "from sklearn.metrics import r2_score, mean_squared_log_error, mean_squared_error,mean_absolute_error\n",
                "import datetime as dt\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "from sklearn.model_selection import train_test_split\n",
                "import preparing_data as F"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "data=pd.read_pickle(\"./dataframe/df_20210912_133401_ONLY_RISKY_EVENTS-6-withFE.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(272, 86)\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>__time_to_tca</th>\n",
                            "      <th>MISS_DISTANCE</th>\n",
                            "      <th>RELATIVE_SPEED</th>\n",
                            "      <th>RELATIVE_POSITION_R</th>\n",
                            "      <th>RELATIVE_POSITION_T</th>\n",
                            "      <th>RELATIVE_POSITION_N</th>\n",
                            "      <th>RELATIVE_VELOCITY_R</th>\n",
                            "      <th>RELATIVE_VELOCITY_T</th>\n",
                            "      <th>RELATIVE_VELOCITY_N</th>\n",
                            "      <th>COLLISSION_PROBABILITY</th>\n",
                            "      <th>...</th>\n",
                            "      <th>PC_mavg_1</th>\n",
                            "      <th>PC_trend_1</th>\n",
                            "      <th>PC_trend_3</th>\n",
                            "      <th>PC_gradient_1</th>\n",
                            "      <th>PC_gradient_3</th>\n",
                            "      <th>MD_mavg_1</th>\n",
                            "      <th>MD_trend_1</th>\n",
                            "      <th>MD_trend_3</th>\n",
                            "      <th>MD_gradient_1</th>\n",
                            "      <th>MD_gradient_3</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.832257</td>\n",
                            "      <td>2244.0</td>\n",
                            "      <td>11172.0</td>\n",
                            "      <td>87.9</td>\n",
                            "      <td>-1474.9</td>\n",
                            "      <td>1689.9</td>\n",
                            "      <td>-201.4</td>\n",
                            "      <td>-8424.3</td>\n",
                            "      <td>-7336.0</td>\n",
                            "      <td>-3.418392</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-3.475175</td>\n",
                            "      <td>0.132439</td>\n",
                            "      <td>0.590914</td>\n",
                            "      <td>0.354472</td>\n",
                            "      <td>0.579354</td>\n",
                            "      <td>2181.333333</td>\n",
                            "      <td>47.0</td>\n",
                            "      <td>17.0</td>\n",
                            "      <td>125.795356</td>\n",
                            "      <td>16.667421</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.580855</td>\n",
                            "      <td>966.0</td>\n",
                            "      <td>212.0</td>\n",
                            "      <td>191.0</td>\n",
                            "      <td>-944.8</td>\n",
                            "      <td>-68.9</td>\n",
                            "      <td>33.8</td>\n",
                            "      <td>-8.4</td>\n",
                            "      <td>209.3</td>\n",
                            "      <td>-3.711974</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-3.981494</td>\n",
                            "      <td>0.310256</td>\n",
                            "      <td>0.575376</td>\n",
                            "      <td>0.747481</td>\n",
                            "      <td>0.536846</td>\n",
                            "      <td>1131.000000</td>\n",
                            "      <td>-201.0</td>\n",
                            "      <td>-326.0</td>\n",
                            "      <td>-484.256505</td>\n",
                            "      <td>-304.169574</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.189825</td>\n",
                            "      <td>1102.0</td>\n",
                            "      <td>212.0</td>\n",
                            "      <td>193.3</td>\n",
                            "      <td>-1083.1</td>\n",
                            "      <td>-75.0</td>\n",
                            "      <td>33.9</td>\n",
                            "      <td>-8.4</td>\n",
                            "      <td>209.3</td>\n",
                            "      <td>-3.913996</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-3.882734</td>\n",
                            "      <td>-0.202022</td>\n",
                            "      <td>0.296282</td>\n",
                            "      <td>-0.516640</td>\n",
                            "      <td>0.270366</td>\n",
                            "      <td>1078.333333</td>\n",
                            "      <td>136.0</td>\n",
                            "      <td>-158.0</td>\n",
                            "      <td>347.799165</td>\n",
                            "      <td>-144.179478</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.994637</td>\n",
                            "      <td>456.0</td>\n",
                            "      <td>11707.0</td>\n",
                            "      <td>-22.1</td>\n",
                            "      <td>288.8</td>\n",
                            "      <td>353.3</td>\n",
                            "      <td>-10.2</td>\n",
                            "      <td>-9077.7</td>\n",
                            "      <td>7392.6</td>\n",
                            "      <td>-2.055073</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-2.841298</td>\n",
                            "      <td>1.280567</td>\n",
                            "      <td>1.312874</td>\n",
                            "      <td>3.634346</td>\n",
                            "      <td>1.445698</td>\n",
                            "      <td>709.666667</td>\n",
                            "      <td>-577.0</td>\n",
                            "      <td>124.0</td>\n",
                            "      <td>-1637.570088</td>\n",
                            "      <td>136.545083</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.759012</td>\n",
                            "      <td>629.0</td>\n",
                            "      <td>11707.0</td>\n",
                            "      <td>-18.7</td>\n",
                            "      <td>395.3</td>\n",
                            "      <td>489.9</td>\n",
                            "      <td>-10.3</td>\n",
                            "      <td>-9077.7</td>\n",
                            "      <td>7392.6</td>\n",
                            "      <td>-2.649558</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-2.680091</td>\n",
                            "      <td>-0.594485</td>\n",
                            "      <td>0.483623</td>\n",
                            "      <td>-2.523011</td>\n",
                            "      <td>0.486607</td>\n",
                            "      <td>706.000000</td>\n",
                            "      <td>173.0</td>\n",
                            "      <td>-11.0</td>\n",
                            "      <td>734.217036</td>\n",
                            "      <td>-11.067877</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 86 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   __time_to_tca  MISS_DISTANCE  RELATIVE_SPEED  RELATIVE_POSITION_R  \\\n",
                            "0       0.832257         2244.0         11172.0                 87.9   \n",
                            "1       0.580855          966.0           212.0                191.0   \n",
                            "2       0.189825         1102.0           212.0                193.3   \n",
                            "3       0.994637          456.0         11707.0                -22.1   \n",
                            "4       0.759012          629.0         11707.0                -18.7   \n",
                            "\n",
                            "   RELATIVE_POSITION_T  RELATIVE_POSITION_N  RELATIVE_VELOCITY_R  \\\n",
                            "0              -1474.9               1689.9               -201.4   \n",
                            "1               -944.8                -68.9                 33.8   \n",
                            "2              -1083.1                -75.0                 33.9   \n",
                            "3                288.8                353.3                -10.2   \n",
                            "4                395.3                489.9                -10.3   \n",
                            "\n",
                            "   RELATIVE_VELOCITY_T  RELATIVE_VELOCITY_N  COLLISSION_PROBABILITY  ...  \\\n",
                            "0              -8424.3              -7336.0               -3.418392  ...   \n",
                            "1                 -8.4                209.3               -3.711974  ...   \n",
                            "2                 -8.4                209.3               -3.913996  ...   \n",
                            "3              -9077.7               7392.6               -2.055073  ...   \n",
                            "4              -9077.7               7392.6               -2.649558  ...   \n",
                            "\n",
                            "   PC_mavg_1  PC_trend_1  PC_trend_3  PC_gradient_1  PC_gradient_3  \\\n",
                            "0  -3.475175    0.132439    0.590914       0.354472       0.579354   \n",
                            "1  -3.981494    0.310256    0.575376       0.747481       0.536846   \n",
                            "2  -3.882734   -0.202022    0.296282      -0.516640       0.270366   \n",
                            "3  -2.841298    1.280567    1.312874       3.634346       1.445698   \n",
                            "4  -2.680091   -0.594485    0.483623      -2.523011       0.486607   \n",
                            "\n",
                            "     MD_mavg_1  MD_trend_1  MD_trend_3  MD_gradient_1  MD_gradient_3  \n",
                            "0  2181.333333        47.0        17.0     125.795356      16.667421  \n",
                            "1  1131.000000      -201.0      -326.0    -484.256505    -304.169574  \n",
                            "2  1078.333333       136.0      -158.0     347.799165    -144.179478  \n",
                            "3   709.666667      -577.0       124.0   -1637.570088     136.545083  \n",
                            "4   706.000000       173.0       -11.0     734.217036     -11.067877  \n",
                            "\n",
                            "[5 rows x 86 columns]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "data.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(272, 86)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "train, test = train_test_split(data, test_size=0.30, random_state=42)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "print(\"Train dataframe dimension {} x {}\".format(train.shape[0],train.shape[1]))\n",
                "print(\"Test dataframe dimension {} x {}\".format(test.shape[0],test.shape[1]))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Train dataframe dimension 190 x 86\n",
                        "Test dataframe dimension 82 x 86\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "Y_train = train[\"COLLISSION_PROBABILITY\"]\n",
                "X_train= train.drop([\"COLLISSION_PROBABILITY\"], axis=1)\n",
                "Y_test = test[\"COLLISSION_PROBABILITY\"]\n",
                "X_test= test.drop([\"COLLISSION_PROBABILITY\"], axis=1)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# improving function\n",
                "def bayesian_opt_lgbm(X, y, init_iter=3, n_iters=7, random_state=11, seed = 101, num_iterations = 100,evalm=\"lgb_r2\"):\n",
                "      dtrain = lgb.Dataset(data=X, label=y)\n",
                "      #Metric evaluation functions\n",
                "      def lgb_r2(preds, dtrain):                #R2\n",
                "            labels = dtrain.get_label()\n",
                "            return 'metric', r2_score(labels, preds), True\n",
                "      def lgb_rmse(preds, dtrain):      #RMSE\n",
                "            labels = dtrain.get_label()\n",
                "            return 'metric', mean_squared_error(labels, preds,squared=False), True\n",
                "      def lgb_mae(preds, dtrain):     #MAE\n",
                "            labels = dtrain.get_label()\n",
                "            return 'metric', mean_absolute_error(labels, preds), True\n",
                "      def lgb_adjusted_r2(preds, dtrain):       #ADJUSTED R2\n",
                "            labels = dtrain.get_label()\n",
                "            n=dtrain.num_data()\n",
                "            k=dtrain.num_feature()\n",
                "            return 'metric', ((1-r2_score(labels, preds))*(n-1))/(n-k-1), True\n",
                "\n",
                "\n",
                "      metrics_dict= {   \"lgb_r2\" : lgb_r2,\n",
                "                        \"lgb_rmse\":lgb_rmse,\n",
                "                        \"lgb_mae\":lgb_mae,\n",
                "                        \"lgb_adjusted_r2\": lgb_adjusted_r2\n",
                "                        }\n",
                "      # Select metric\n",
                "      metric=str(evalm)\n",
                "      metric_feval=metrics_dict.get(str(evalm))\n",
                "\n",
                "      # Objective Function\n",
                "      def hyp_lgbm(num_leaves, feature_fraction, learning_rate, bagging_fraction, max_depth, min_split_gain, min_child_weight):\n",
                "              params = {      'application':'regression',\n",
                "                              'num_iterations': num_iterations,\n",
                "                              'early_stopping_round':50,\n",
                "                              'verbose':-1,\n",
                "                              'metric':metric} # Default parameters\n",
                "              params[\"num_leaves\"] = int(round(num_leaves))\n",
                "              params[\"learning_rate\"] = learning_rate\n",
                "              params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
                "              params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
                "              params['max_depth'] = int(round(max_depth))\n",
                "              params['min_split_gain'] = min_split_gain\n",
                "              params['min_child_weight'] = min_child_weight\n",
                "              cv_results = lgb.cv(params, dtrain, nfold=5, seed=seed,categorical_feature=[], stratified=False,\n",
                "                                  verbose_eval =None, feval=metric_feval)\n",
                "              #print(cv_results)\n",
                "              return np.max(cv_results['metric-mean'])\n",
                "    \n",
                "              # Domain space-- Range of hyperparameters \n",
                "      pds = {     'num_leaves': (60, 120),\n",
                "                  'feature_fraction': (0.1, 0.9),\n",
                "                  'bagging_fraction': (0.7, 1),\n",
                "                  'max_depth': (7, 15),\n",
                "                  'learning_rate':(0.001,0.05), \n",
                "                  'min_split_gain': (0.001, 0.1),\n",
                "                  'min_child_weight': (10, 35)\n",
                "                  }\n",
                "      # Surrogate model\n",
                "      optimizer = BayesianOptimization(hyp_lgbm, pds, random_state=random_state)\n",
                "                                          \n",
                "      # Optimize\n",
                "      optimizer.maximize(init_points=init_iter, n_iter=n_iters)\n",
                "\n",
                "      # Output dictionary\n",
                "      output_dict=optimizer.max['params']\n",
                "      output_dict[\"num_iterations\"]=num_iterations\n",
                "      output_dict[\"n_estimators\"]=n_iters\n",
                "\n",
                "      # Save dictionary to file\n",
                "      filename=\"./opt_parameters_bo/param_{}_{}.pkl\".format(dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\"),metric)\n",
                "      a_file = open(filename, \"wb\")\n",
                "      pickle.dump(output_dict, a_file)\n",
                "      a_file.close()\n",
                "\n",
                "      return optimizer,output_dict"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "def compare_true_vs_prediction(df_true,df_pred):\n",
                "    aux_y=pd.DataFrame(df_true)\n",
                "    aux_y.reset_index(inplace=True)\n",
                "    aux_y.drop(['index'], inplace=True, axis=1)\n",
                "    aux_y_pred=pd.DataFrame(df_pred)\n",
                "    aux_y_pred.reset_index(inplace=True)\n",
                "    aux_y_pred.drop(['index'], inplace=True, axis=1)\n",
                "    frames=[aux_y,aux_y_pred]\n",
                "    result=pd.concat(frames,axis=1)\n",
                "    result.columns=[\"y_true\",\"y_predicted\"]\n",
                "    result[\"y_true_10\"]=10**result.y_true\n",
                "    result[\"y_predicted_10\"]=10**result.y_predicted\n",
                "    result[result[\"y_true_10\"]>0.00001]\n",
                "    result[result[\"y_true_10\"]>0.0001]\n",
                "    return result\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "def create_and_validate_model(X, y, \n",
                "                            init_iter=5, n_iters=500, random_state=77, seed = 101,num_iterations=300,\n",
                "                            evalm=\"lgb_r2\",hp_metric=\"regression_L2\"):\n",
                "    bayesian=bayesian_opt_lgbm(X, y, init_iter, n_iters, random_state, seed,num_iterations,evalm)\n",
                "    opt_parameters=bayesian[1]\n",
                "    print(\"------------------------ OPTIMAL PARAMETERS ------------------------\")\n",
                "    print(opt_parameters)\n",
                "    print(\"-------------------------------------------------------------------\")\n",
                "    \n",
                "    # LOAD OPTIMAL PARAMETERS FOR FURTHER COMPUTATION\n",
                "    hyper_params = {\n",
                "                    'task': 'train',\n",
                "                    'boosting_type': 'gbdt',\n",
                "                    'objective': 'regression',\n",
                "                    'metric': str(hp_metric),\n",
                "                    'learning_rate': opt_parameters.get(\"learning_rate\"),\n",
                "                    'feature_fraction': opt_parameters.get(\"feature_fraction\"),\n",
                "                    'bagging_fraction': opt_parameters.get(\"bagging_fraction\"),\n",
                "                    'verbose': -1,\n",
                "                    \"max_depth\": int(round(opt_parameters.get(\"max_depth\"))),\n",
                "                    \"num_leaves\": int(round(opt_parameters.get(\"num_leaves\"))),  \n",
                "                    'min_split_gain' : opt_parameters.get(\"min_split_gain\"),\n",
                "                    \"num_iterations\": opt_parameters.get(\"num_iterations\"),\n",
                "                    \"n_estimators\": opt_parameters.get(\"n_estimators\"),\n",
                "                    'min_child_weight' : opt_parameters.get(\"min_child_weight\")\n",
                "                    }\n",
                "    # TRAIN MODEL WITH OPTIMAL PARAMETERS\n",
                "    lgbm_train = lgb.Dataset(X, label=y)\n",
                "    gbm = lgb.train(params=hyper_params,train_set=lgbm_train)\n",
                "\n",
                "    # TEST MODEL WITH TESTING SUBPART OF DATASET\n",
                "    Y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
                "\n",
                "    # REGRESION MODEL METRICS\n",
                "    print('The r2 of prediction is:', r2_score(Y_test, Y_pred))\n",
                "    print('The MSE of prediction is:', mean_squared_error(Y_test, Y_pred, squared=True))\n",
                "    print('The RMSE of prediction is:', mean_squared_error(Y_test, Y_pred, squared=False))\n",
                "    print('The MAE of prediction is:', mean_absolute_error(Y_test, Y_pred))\n",
                "\n",
                "    # COMPARE TEST VALUES VS PREDICTED VALUES\n",
                "    df_results=compare_true_vs_prediction(df_true=Y_test,df_pred=Y_pred)\n",
                "\n",
                "    # WRITE TO A FILE\n",
                "    \n",
                "    outF = open(\"./validation-results/r_{}.txt\".format(dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")), \"w+\")\n",
                "    # write line to output file\n",
                "    outF.write(\"------------------------- MODEL HYPER-PARAMETERS ------------------------- \\n\")\n",
                "    outF.write(str(hyper_params))\n",
                "    outF.write(\"\\n\")\n",
                "    outF.write(\"\\n\")\n",
                "    outF.write(\"------------------------ REGRESSION MODEL METRICS ------------------------ \\n\")\n",
                "    outF.write(str('The r2 of prediction is: ') + str(r2_score(Y_test, Y_pred))+str(\"\\n\"))\n",
                "    outF.write(str('The MSE of prediction is: ') + str(mean_squared_error(Y_test, Y_pred, squared=True))+str(\"\\n\"))\n",
                "    outF.write(str('The RMSE of prediction is: ')+ str(mean_squared_error(Y_test, Y_pred, squared=False))+str(\"\\n\"))\n",
                "    outF.write(str('The MAE of prediction is: ')+ str(mean_absolute_error(Y_test, Y_pred))+str(\"\\n\"))\n",
                "    outF.write(\"\\n\")\n",
                "    outF.write(\"\\n\")\n",
                "    outF.write(\"-------------------------- ADDITIONAL COMMENTS -------------------------- \\n\")\n",
                "    outF.write(str(\"This model was created and validated at {}\".format(dt.datetime.fromtimestamp(dt.datetime.timestamp(dt.datetime.now())))))\n",
                "    outF.close()\n",
                "\n",
                "    return gbm, df_results"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "model=create_and_validate_model(X, y,\n",
                "                        init_iter=5, n_iters=1000, random_state=77, seed = 101,num_iterations=300,evalm=\"lgb_mae\",hp_metric=\"mae\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_ch... | min_sp... | num_le... |\n",
                        "-------------------------------------------------------------------------------------------------------------\n",
                        "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5654  \u001b[0m | \u001b[0m 0.9757  \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 0.03793 \u001b[0m | \u001b[0m 8.115   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 0.07901 \u001b[0m | \u001b[0m 79.57   \u001b[0m |\n",
                        "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5664  \u001b[0m | \u001b[95m 0.8623  \u001b[0m | \u001b[95m 0.2922  \u001b[0m | \u001b[95m 0.02773 \u001b[0m | \u001b[95m 10.2    \u001b[0m | \u001b[95m 27.88   \u001b[0m | \u001b[95m 0.08383 \u001b[0m | \u001b[95m 95.31   \u001b[0m |\n",
                        "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5643  \u001b[0m | \u001b[0m 0.7888  \u001b[0m | \u001b[0m 0.3248  \u001b[0m | \u001b[0m 0.03557 \u001b[0m | \u001b[0m 10.38   \u001b[0m | \u001b[0m 11.43   \u001b[0m | \u001b[0m 0.07496 \u001b[0m | \u001b[0m 87.14   \u001b[0m |\n",
                        "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.5702  \u001b[0m | \u001b[95m 0.7527  \u001b[0m | \u001b[95m 0.1395  \u001b[0m | \u001b[95m 0.01533 \u001b[0m | \u001b[95m 7.534   \u001b[0m | \u001b[95m 28.78   \u001b[0m | \u001b[95m 0.007313\u001b[0m | \u001b[95m 85.91   \u001b[0m |\n",
                        "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5685  \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.02779 \u001b[0m | \u001b[0m 10.55   \u001b[0m | \u001b[0m 10.9    \u001b[0m | \u001b[0m 0.08247 \u001b[0m | \u001b[0m 76.4    \u001b[0m |\n",
                        "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5663  \u001b[0m | \u001b[0m 0.9346  \u001b[0m | \u001b[0m 0.3943  \u001b[0m | \u001b[0m 0.0391  \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 33.97   \u001b[0m | \u001b[0m 0.04177 \u001b[0m | \u001b[0m 60.81   \u001b[0m |\n",
                        "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5654  \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 0.04408 \u001b[0m | \u001b[0m 7.681   \u001b[0m | \u001b[0m 34.7    \u001b[0m | \u001b[0m 0.09668 \u001b[0m | \u001b[0m 119.8   \u001b[0m |\n",
                        "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5666  \u001b[0m | \u001b[0m 0.8209  \u001b[0m | \u001b[0m 0.7184  \u001b[0m | \u001b[0m 0.03572 \u001b[0m | \u001b[0m 7.241   \u001b[0m | \u001b[0m 34.11   \u001b[0m | \u001b[0m 0.09998 \u001b[0m | \u001b[0m 60.09   \u001b[0m |\n",
                        "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.5705  \u001b[0m | \u001b[95m 0.7702  \u001b[0m | \u001b[95m 0.5718  \u001b[0m | \u001b[95m 0.008441\u001b[0m | \u001b[95m 7.378   \u001b[0m | \u001b[95m 34.91   \u001b[0m | \u001b[95m 0.01675 \u001b[0m | \u001b[95m 60.27   \u001b[0m |\n",
                        "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.5711  \u001b[0m | \u001b[95m 0.824   \u001b[0m | \u001b[95m 0.1727  \u001b[0m | \u001b[95m 0.006168\u001b[0m | \u001b[95m 7.595   \u001b[0m | \u001b[95m 34.33   \u001b[0m | \u001b[95m 0.06562 \u001b[0m | \u001b[95m 60.03   \u001b[0m |\n",
                        "=============================================================================================================\n",
                        "------------------------ OPTIMAL PARAMETERS ------------------------\n",
                        "{'bagging_fraction': 0.8239842963664266, 'feature_fraction': 0.17269420157651066, 'learning_rate': 0.006167554487121441, 'max_depth': 7.594601637154401, 'min_child_weight': 34.326548142148006, 'min_split_gain': 0.06562319313831345, 'num_leaves': 60.030840198395076, 'num_iterations': 300, 'n_estimators': 5}\n",
                        "-------------------------------------------------------------------\n",
                        "The r2 of prediction is: 0.015099385200401105\n",
                        "The MSE of prediction is: 0.5439047849078525\n",
                        "The RMSE of prediction is: 0.7374990067165192\n",
                        "The MAE of prediction is: 0.5842268047039432\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# filename=\"./opt_parameters_bo/param_20210912_213528_lgb_r2.pkl\"\n",
                "# a_file = open(filename,\"rb\")\n",
                "# output = pickle.load(a_file)\n",
                "# opt_parameters=output\n",
                "# output"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.6 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "2e85db0d6cccfdde710fbbd04098e00f256a22b321d8c0df509f8fabaad6d9ac"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}