{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\n",
                "import datetime as dt\n",
                "#from datetime import datetime, timedelta\n",
                "import numpy as np\n",
                "import os\n",
                "pd.set_option('display.max_rows', 100)\n",
                "pd.set_option('display.max_columns', 1000)\n",
                "pd.set_option('display.width', 1000)\n",
                "\n",
                "\n",
                "\n",
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_log_error\n",
                "from sklearn import preprocessing\n",
                "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
                "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "\n",
                "\n",
                "# Bayesian optimization\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "from bayes_opt import BayesianOptimization\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
                "from sklearn.model_selection import KFold, cross_val_score\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data=pd.read_pickle(\"full_dataframe_20210803_150443.pkl\")\n",
                "data.reset_index(inplace=True)\n",
                "data.drop(['index','event_id'], inplace=True, axis=1)\n",
                "print(data.shape)\n",
                "data.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data=data.head(500)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "data.shape"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train, test = train_test_split(data, test_size=0.20, random_state=42)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "Y_train = train[\"COLLISSION_PROBABILITY_TARGET\"]\n",
                "X_train= train.drop([\"COLLISSION_PROBABILITY_TARGET\"], axis=1)\n",
                "Y_test = test[\"COLLISSION_PROBABILITY_TARGET\"]\n",
                "X_test= test.drop([\"COLLISSION_PROBABILITY_TARGET\"], axis=1)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "X = X_train\n",
                "y = Y_train"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\"\"\" params = {\n",
                "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
                "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
                "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
                "        }\n",
                "train_data = lgb.Dataset(data=X, label=y, categorical_feature = list(X.columns),free_raw_data=False)\n",
                "    \n",
                "cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False,shuffle=False) \"\"\"\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\"\"\" def lgb_eval(num_leaves, feature_fraction, max_depth , min_split_gain, min_child_weight):\n",
                "    params = {\n",
                "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
                "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
                "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
                "        }\n",
                "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
                "    params['max_depth'] = int(round(max_depth))\n",
                "    params['num_leaves'] = int(round(num_leaves))\n",
                "    params['min_split_gain'] = min_split_gain\n",
                "    params['min_child_weight'] = min_child_weight\n",
                "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
                "    return (-1.0 * np.array(cv_result['rmse-mean'])).max() \"\"\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\"\"\" lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.1, 0.9),\n",
                "                                            'max_depth': (5, 9),\n",
                "                                            'num_leaves' : (200,300),\n",
                "                                            'min_split_gain': (0.001, 0.1),\n",
                "                                            'min_child_weight': (5, 50)}, random_state=0) \"\"\"\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#lgbBO.maximize(init_points=5, n_iter=5,acq='ei')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=0, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
                "    # prepare data\n",
                "    train_data = lgb.Dataset(data=X, label=y, categorical_feature = list(X.columns),free_raw_data=False)\n",
                "    # parameters\n",
                "\n",
                "    def lgb_eval(num_leaves, feature_fraction, max_depth , min_split_gain, min_child_weight):\n",
                "        params = {\n",
                "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
                "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
                "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
                "        }\n",
                "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
                "        params['max_depth'] = int(round(max_depth))\n",
                "        params['num_leaves'] = int(round(num_leaves))\n",
                "        params['min_split_gain'] = min_split_gain\n",
                "        params['min_child_weight'] = min_child_weight\n",
                "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, verbose_eval =200,stratified=False)\n",
                "        return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
                "    \n",
                "        # range \n",
                "    lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.1, 0.9),\n",
                "                                            'max_depth': (5, 9),\n",
                "                                            'num_leaves' : (200,300),\n",
                "                                            'min_split_gain': (0.001, 0.1),\n",
                "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
                "        # optimize\n",
                "    lgbBO.maximize(init_points=init_round, n_iter=opt_round,acq='ei')\n",
                "\n",
                "        # output optimization process\n",
                "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
                "\n",
                "        # return best parameters\n",
                "    return lgbBO.res['max']['max_params']\n",
                "\n",
                "opt_params = bayes_parameter_opt_lgb(X, y, init_round=10, opt_round=10, n_folds=5, random_seed=0, n_estimators=1000, learning_rate=0.01)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.6 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "2e85db0d6cccfdde710fbbd04098e00f256a22b321d8c0df509f8fabaad6d9ac"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}